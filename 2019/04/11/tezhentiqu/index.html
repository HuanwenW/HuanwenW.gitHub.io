<!DOCTYPE html>
<html lang="en">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
  <meta name="keywords" content="hexo,个人博客,blog">
  <meta name="description" content="焕小妹的个人博客">
  <meta http-equiv="x-dns-prefetch-control" content="on">
  <link rel="dns-prefetch" href="https://busuanzi.ibruce.info">
  <link rel="dns-prefetch" href="https://at.alicdn.com">
  
  <link rel="dns-prefetch" href="https://widget.daovoice.io">
  <link rel="dns-prefetch" href="https://widget-static-cdn.daovoice.io">
  <link rel="dns-prefetch" href="https://im.daovoice.io">
  
  
  <link rel="dns-prefetch" href="https://hm.baidu.com/">
  
  
  <link rel="dns-prefetch" href="https://cdn.jsdelivr.net">
  <link rel="dns-prefetch" href="https://api.github.com">
  <link rel="dns-prefetch" href="https://avatars3.githubusercontent.com">
  
  <link rel="stylesheet" type="text/css" href="/./style/main.css">
	<link rel="shortcut icon" href="/favicon.ico" title="Favicon">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
	<title>Welcome to NLP-2019-huanhuan-homework-3</title>
  
  <script>var _hmt=_hmt||[];(function(){var hm=document.createElement("script");hm.src="https://hm.baidu.com/hm.js?be13bf98b13bee6a1fc89b6ae36a8ffb";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(hm,s);})();
  </script>
  
  
    <script>(function(i,s,o,g,r,a,m){i["DaoVoiceObject"]=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;a.charset="utf-8";m.parentNode.insertBefore(a,m)})(window,document,"script",('https:' == document.location.protocol ? 'https:' : 'http:') + "//widget.daovoice.io/widget/a1aef33b.js","daovoice");daovoice('init',{app_id: "a1aef33b"});daovoice('update');
  </script>
  
</head>
<body>
  <canvas id="pattern-placeholder" height="230"></canvas>
<div class="navbar-header">
  <a class="blog-title" href="/">焕小妹的博客</a>
  <a class="face-img" href="/">
    <img src="https://github.com/HuanwenW/MyPostImag/blob/master/190410-boke/touxiang-1.jpg?raw=true">
  </a>
</div>
<main>
  <div class="article-title">
    
  
  <h1 class="title">
    Welcome to NLP-2019-huanhuan-homework-3
  </h1>
  


    <ul class="article-info">
      <li>
        发布
        <time datetime="2019-04-11T12:44:17.000Z" itemprop="datePublished">2019-04-11</time>
      </li>
      <li>
        
    更新 <time datetime="2019-04-12T08:02:42.000Z" itemprop="dateUpdated">2019-04-12</time>

      </li>
      <li id="busuanzi_container_page_pv">
        阅读 <span id="busuanzi_value_page_pv"></span>
      </li>
    </ul>
  </div>
  <div class="container">
    <div class="article">
      <div class="content">
        
        <div class="overdue-remind">
          本文最后更新于$day天前，文中所描述的信息可能已发生改变。
        </div>
        
        <h2 id="内容涵盖"><a href="#内容涵盖" class="headerlink" title="内容涵盖"></a>内容涵盖</h2><ul>
<li>分词的正向最大、逆向最大、双向最大匹配法概念；</li>
<li>词、字符频率统计；（可以使用Python中的collections.Counter模块，也可以自己寻找其他好用的库）</li>
<li>语言模型中unigram、bigram、trigram的概念；</li>
<li>unigram、bigram频率统计；（可以使用Python中的collections.Counter模块，也可以自己寻找其他好用的库）</li>
<li>文本矩阵化：要求采用词袋模型且是词级别的矩阵化<br>步骤有：<br>3.1 分词（可采用结巴分词来进行分词操作，其他库也可以）；<br>3.2 去停用词；构造词表。<br>3.3 每篇文档的向量化。  </li>
</ul>
<h2 id="1-基本文本处理技能"><a href="#1-基本文本处理技能" class="headerlink" title="1. 基本文本处理技能"></a>1. 基本文本处理技能</h2><p>&ensp;&ensp;&ensp;Python中分分词工具很多，包括盘古分词、Yaha分词、Jieba分词、清华THULAC等。它们的基本用法都大同小异，本文以结巴分词 为例.  </p>
<p><strong>(1) 分词算法设计中的几个基本原则：</strong>  </p>
<p><strong>a.</strong>颗粒度越大越好：用于进行语义分析的文本分词，要求分词结果的颗粒度越大，即单词的字数越多，所能表示的含义越确切，如：“公安局长”可以分为“公安 局长”、“公安局 长”、“公安局长”都算对，但是要用于语义分析，则“公安局长”的分词结果最好（当然前提是所使用的词典中有这个词）</p>
<p><strong>b.</strong>切分结果中非词典词越少越好，单字字典词数越少越好，这里的“非词典词”就是不包含在词典中的单字，而“单字字典词”指的是可以独立运用的单字，如“的”、“了”、“和”、“你”、“我”、“他”。例如：“技术和服务”，可以分为“技术 和服 务”以及“技术 和 服务”，但“务”字无法独立成词（即词典中没有），但“和”字可以单独成词（词典中要包含），因此“技术 和服 务”有1个非词典词，而“技术 和 服务”有0个非词典词，因此选用后者。</p>
<p><strong>c.</strong>总体词数越少越好，在相同字数的情况下，总词数越少，说明语义单元越少，那么相对的单个语义单元的权重会越大，因此准确性会越高。</p>
<p><strong>(2) 匹配法：</strong><br>&ensp;&ensp;&ensp;最大匹配是指以词典为依据，取词典中最长单词为第一个次取字数量的扫描串，在词典中进行扫描（为提升扫描效率，还可以跟据字数多少设计多个字典，然后根据字数分别从不同字典中进行扫描）。例如：词典中最长词为“我爱北京天安门”共7个汉字，则最大匹配起始字数为7个汉字。然后逐字递减，在对应的词典中进行查找。<br><font color="#8A2BE2" size="3"><strong>&ensp;&ensp;下面以“我们在野生动物园玩”详细说明一下这几种匹配方法：</strong></font>       </p>
<p><strong>a. 正向最大匹配法</strong>  </p>
<p><strong>正向即从前往后取词，从7-&gt;1，每次减一个字，直到词典命中或剩下1个单字。</strong>   </p>
<p>第1次：“我们在野生动物”，扫描7字词典，无<br>第2次：“我们在野生动”，扫描6字词典，无<br><strong>……</strong><br>第6次：“我们”，扫描2字词典，有  </p>
<p><strong>扫描中止，输出第1个词为“我们”，去除第1个词后开始第2轮扫描，即：</strong>  </p>
<p>第1次：“在野生动物园玩”，扫描7字词典，无<br>第2次：“在野生动物园”，扫描6字词典，无<br><strong>……</strong><br>第6次：“在野”，扫描2字词典，有  </p>
<p><strong>扫描中止，输出第2个词为“在野”，去除第2个词后开始第3轮扫描，即：</strong>    </p>
<p>第1次：“生动物园玩”，扫描5字词典，无<br><strong>……</strong><br>第4次：“生动”，扫描2字词典，有</p>
<p><strong>扫描中止，输出第3个词为“生动”，第4轮扫描，即：</strong>    </p>
<p>第1次：“物园玩”，扫描3字词典，无<br>第2次：“物园”，扫描2字词典，无<br>第3次：“物”，扫描1字词典，无  </p>
<p><strong>扫描中止，输出第4个词为“物”，非字典词数加1，开始第5轮扫描，即：</strong>    </p>
<p>第1次：“园玩”，扫描2字词典，无<br>第2次：“园”，扫描1字词典，有  </p>
<p><strong>扫描中止，输出第5个词为“园”，单字字典词数加1，开始第6轮扫描，即：</strong>    </p>
<p>第1次：“玩”，扫描1字字典词，有</p>
<p><strong>扫描中止，输出第6个词为“玩”，单字字典词数加1，整体扫描结束。</strong>   </p>
<p><font color="#8A2BE2" size="3">*<em>正向最大匹配法，最终切分结果为：“我们/在野/生动/物/园/玩”，其中，单字字典词为2，非词典词为1。  *</em></font>   </p>
<p>*<em>b.逆向最大匹配法  *</em>  </p>
<p><strong>逆向即从后往前取词，其他逻辑和正向相同。即：</strong></p>
<p>第1轮扫描：“在野生动物园玩”<br>第1次：“在野生动物园玩”，扫描7字词典，无<br>第2次：“野生动物园玩”，扫描6字词典，无<br><strong>……</strong><br>第7次：“玩”，扫描1字词典，有  </p>
<p><strong>扫描中止，输出“玩”，单字字典词加1，开始第2轮扫描</strong>  </p>
<p>第2轮扫描：“们在野生动物园”<br>第1次：“们在野生动物园”，扫描7字词典，无<br>第2次：“在野生动物园”，扫描6字词典，无<br>第3次：“野生动物园”，扫描5字词典，有  </p>
<p><strong>扫描中止，输出“野生动物园”，开始第3轮扫描</strong></p>
<p>第3轮扫描：“我们在”<br>第1次：“我们在”，扫描3字词典，无<br>第2次：“们在”，扫描2字词典，无<br>第3次：“在”，扫描1字词典，有  </p>
<p><strong>扫描中止，输出“在”，单字字典词加1，开始第4轮扫描</strong></p>
<p>第4轮扫描：“我们”<br>第1次：“我们”，扫描2字词典，有  </p>
<p><strong>扫描中止，输出“我们”，整体扫描结束。</strong></p>
<p><font color="#8A2BE2" size="3"><strong>逆向最大匹配法，最终切分结果为：“我们/在/野生动物园/玩”，其中，单字字典词为2，非词典词为0。</strong></font>    </p>
<p><strong>c.双向最大匹配法</strong>     </p>
<p>&ensp;&ensp;&ensp;正向最大匹配法和逆向最大匹配法，都有其局限性，我举得例子是正向最大匹配法局限性的例子，逆向也同样存在（如：长春药店，逆向切分为“长/春药店”），因此有人又提出了双向最大匹配法，双向最大匹配法。即，两种算法都切一遍，然后根据大颗粒度词越多越好，非词典词和单字词越少越好的原则，选取其中一种分词结果输出。  </p>
<p>如：“我们在野生动物园玩”  </p>
<p>正向最大匹配法，最终切分结果为：“我们/在野/生动/物/园/玩”，其中，两字词3个，单字字典词为2，非词典词为1。  </p>
<p>逆向最大匹配法，最终切分结果为：“我们/在/野生动物园/玩”，其中，五字词1个，两字词1个，单字字典词为2，非词典词为0。  </p>
<p>非字典词：正向(1)&gt;逆向(0)（越少越好）  </p>
<p>单字字典词：正向(2)=逆向(2)（越少越好）  </p>
<p>总词数：正向(6)&gt;逆向(4)（越少越好）  </p>
<p>因此最终输出为逆向结果  </p>
<h2 id="参考博客"><a href="#参考博客" class="headerlink" title="参考博客"></a>参考博客</h2><ol>
<li><a href="https://github.com/fxsjy/jieba" target="_blank" rel="noopener">结巴中文分词理论+实践</a></li>
<li><a href="http://blog.sina.com.cn/s/blog_53daccf401011t74.html" target="_blank" rel="noopener">中文分词基础原则及正向最大匹配法、逆向最大匹配法、双向最大匹配法的分析</a></li>
</ol>

      </div>
        <div class="support-author">
          <p>感谢您的阅读。 🙏
          <a href target="_blank">关于转载请看这里</a>
            <!--<a class="btn-pay"  href="#pay-modal">¥ 打赏支持</a>-->
          </p>
        </div>
        <!--
            <div class="like ">
              <div class="like-button">
                <a id="like-note" href="">
                  <i class="icon-heart"></i>喜欢
                </a>
              </div>
              <span id="likes-count">256</span>
            </div>
        -->
        <div class="otherLink">
          <div class="previous">
          </div>
          <div class="next">
          </div>
        </div>
        <div class="comments" id="comments">
          
<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
<script type="text/javascript">
  const gitalk = new Gitalk({
    clientID: '90a1036ad9349c8b0510',
    clientSecret: '5d7693cc0914fa1b34f43bebc0eb1384f2614759',
    repo: 'https://github.com/HuanwenW/HuanwenW.gitHub.io',
    owner: 'HuanwenW',
    admin: ['HuanwenW'],
    id: location.pathname,      // Ensure uniqueness and length less than 50
    distractionFreeMode: false
  })

  gitalk.render('comments');
</script>


        </div>
      </div>
    </div>
   
</main>
<div class="footer">
  <div class="info">
    <p>
    <a href="https://hexo.io"> Hexo </a> 强力驱动 |
      <a href="https://github.com/Youthink/hexo-themes-yearn"> Yearn </a>
      主题
    </p>
    <p>&copy;2019-2021 焕小妹的博客 豫ICP备1023号</p>
  </div>
</div>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<script>//console
  var consoleConfig = '\n欢迎访问 https://huanwenw.github.io ，围观小猿大圣的博客(づ｡◕‿‿◕｡)づ！\n,\n本博客使用 %cHexo%c 搭建，博客主题为小猿大圣开发的 %chexo-themes-yearn%c ~~~ 🎉🎉🎉 \n\n源码 https://github.com/Youthink/hexo-themes-yearn \n\n如果喜欢可以 star 支持一下 ❤️~\n,\n扫描下面的二维码，在手机上查看博客！\n,https://static.hufangyun.com/blog-url-qrcode-180-180.png,\n 想知道这个效果如何实现的？博客内搜索 console 彩蛋 🚀 ！\n'.split(',');
  var canConsole = true;
  var consoleInfo = (function(consoleConfig) {
  if (!canConsole || !consoleConfig || consoleConfig.length < 1) {
    return;
  }
  var consoleColor = '#6190e8';
  var _console;
  var backgroundTextStyle = 'padding: 1px 5px;color: #fff;background: ' + consoleColor + ';'
  var textStyle = 'color: ' + consoleColor + ';';

  consoleConfig.map(o => {
    var num = (o.match(/%c/g) || []).length;
    if(/^http(s)?:\/\//.test(o)) {
      console.log('%c     ', 'background: url(' + o + ') no-repeat left center;font-size: 180px;');
      return;
    }
    if (num > 0) {
      var logArguments = [];
      for (var i = 0; i < num; i++) {
        if (i % 2 === 0) {
          logArguments.push(backgroundTextStyle);
        } else {
          logArguments.push(textStyle);
        }
      }
      (_console = console).log.apply(_console, ['%c' + o, textStyle].concat(logArguments));
      return;
    }
    console.log('%c' + o, textStyle);
  });
}(consoleConfig));</script><script type="text/javascript" src="/./js/main.js"></script>

  <script src="//at.alicdn.com/t/font_159214_mvtxvg9me9.js"></script>
</body>
</html>
