<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>焕小妹的博客</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-09-20T03:01:10.566Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>焕焕</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>重零开始安装Ubantu18.04+nvidia-410显卡驱+cuda10.0</title>
    <link href="http://yoursite.com/2019/09/20/software-install/ubantuSystem/"/>
    <id>http://yoursite.com/2019/09/20/software-install/ubantuSystem/</id>
    <published>2019-09-20T12:55:27.000Z</published>
    <updated>2019-09-20T03:01:10.566Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>为了paper实验，各种周折后，2019.09入手一台新电脑，显卡配置为<strong>华硕RTX2080Ti</strong>，于是乎小白开始为电脑安装ubantu18.0及系统内nvidia-410显卡驱、CUDA10.0、cuDNN v7.3.1、ananconda3、ananconda2、tensorflow之旅奔波</p><h2 id="友情提醒"><a href="#友情提醒" class="headerlink" title="友情提醒"></a>友情提醒</h2><p>安装过程中所下载好的软件包，备份到<strong>移动硬盘</strong>，防止系统重装，避免浪费不必要的软件下载时间</p><h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>在终端查看CUDNN版本：（附件1）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2</span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://blog.csdn.net/weixin_43820996/article/details/100677482" target="_blank" rel="noopener">Ubuntu18.04安装Cuda10.1/Cudnn</a></li></ol><h2 id="Ubantu-无法识别-（希捷）移动硬盘"><a href="#Ubantu-无法识别-（希捷）移动硬盘" class="headerlink" title="Ubantu 无法识别 （希捷）移动硬盘"></a>Ubantu 无法识别 （希捷）移动硬盘</h2><p>本人的为ubuntu18.04 (64位)，ubuntu14、ubuntu14解决办法应该一样，其他的未测试。</p><p>解决方式如下，运行命令:</p><p>sudo apt-get install exfat-fuse exfat-utils</p><h2 id="参考-1"><a href="#参考-1" class="headerlink" title="参考"></a>参考</h2><p><a href="https://blog.csdn.net/qq_18863573/article/details/54341460" target="_blank" rel="noopener"><strong>Ubuntu无法挂载移动硬盘</strong></a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;为了paper实验，各种周折后，2019.09入手一台新电脑，显卡配置为&lt;strong&gt;华硕RTX2080Ti&lt;/strong&gt;，于是乎小白
      
    
    </summary>
    
    
      <category term="装机篇" scheme="http://yoursite.com/categories/%E8%A3%85%E6%9C%BA%E7%AF%87/"/>
    
    
      <category term="software installs" scheme="http://yoursite.com/tags/software-installs/"/>
    
  </entry>
  
  <entry>
    <title>uUbantu18.04安装nvidia-410显卡驱（华硕2080Ti）</title>
    <link href="http://yoursite.com/2019/09/19/software-install/ubantu18.04%20install%20drive/"/>
    <id>http://yoursite.com/2019/09/19/software-install/ubantu18.04 install drive/</id>
    <published>2019-09-19T13:55:27.000Z</published>
    <updated>2019-09-20T01:02:34.973Z</updated>
    
    <content type="html"><![CDATA[<h2 id="本驱动安装流程简介"><a href="#本驱动安装流程简介" class="headerlink" title="本驱动安装流程简介"></a>本驱动安装流程简介</h2><p><strong>卸载ubantu自带驱动——添加PPA源——安装对应版本的驱动</strong></p><h2 id="具体步骤："><a href="#具体步骤：" class="headerlink" title="具体步骤："></a>具体步骤：</h2><ol><li><p>为了保证不必要的冲突，先卸载原有驱动</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get remove --purge nvidia*   #卸载原有驱动</span><br></pre></td></tr></table></figure></li><li><p>禁用nouveau驱动，<strong>非必要步骤，可跳过</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo gedit /etc/modprobe.d/blacklist.conf  #打开文本</span><br></pre></td></tr></table></figure><p>在打开的文本最后添加以下内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">blacklist nouveau</span><br><span class="line">options nouveau modeset=0</span><br></pre></td></tr></table></figure><p>保存退出后执行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo update-initramfs -u</span><br></pre></td></tr></table></figure><p>（重启后，执行：<code>lsmod | grep nouveau</code>。如果没有屏幕输出，说明禁用nouveau成功。）</p></li><li><p>添加PPA源</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo add-apt-repository ppa:graphics-drivers/ppa</span><br><span class="line">sudo apt-get update</span><br></pre></td></tr></table></figure></li><li><p>安装驱动</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install nvidia-driver-410</span><br></pre></td></tr></table></figure><p>注：软件包的名字需要写正确，比如如果写成下面的会报则会报错  <strong>E：无法定位软件包 nvidia-410</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install nvidia-410</span><br></pre></td></tr></table></figure></li><li><p>安装成功，<strong>重启电脑</strong>，输入下面命令确认是否安装成</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi</span><br></pre></td></tr></table></figure><p>若显示下图则表示安装成功：</p><p><img src="file:///Users/huanw/Library/Application%20Support/typora-user-images/image-20190920081001226.png?lastModify=1568938193" alt="image-20190920081001226"><span class="img-alt">image-20190920081001226</span></p></li></ol><ol start="6"><li><p>各参数含义</p><p>表格第一行：分别表示 nvidia显卡对应的版本：410.104，CUDA版本：10.0</p><p>注意：<strong>电脑后期装cuda需同显卡版本对应，即cuda版本为10.0</strong>,<a href>安装cuda10请跳转本链接</a></p><p>表格第二行依次为风扇等</p><p>表格下面的processes表示现在电脑的进程使用情况</p></li></ol><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol><li><a href="https://blog.csdn.net/u012796629/article/details/86583560" target="_blank" rel="noopener">ubuntu18.04 安装nvidia显卡驱动</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;本驱动安装流程简介&quot;&gt;&lt;a href=&quot;#本驱动安装流程简介&quot; class=&quot;headerlink&quot; title=&quot;本驱动安装流程简介&quot;&gt;&lt;/a&gt;本驱动安装流程简介&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;卸载ubantu自带驱动——添加PPA源——安装对应版本的驱动&lt;/s
      
    
    </summary>
    
    
      <category term="装机篇" scheme="http://yoursite.com/categories/%E8%A3%85%E6%9C%BA%E7%AF%87/"/>
    
    
      <category term="software installs" scheme="http://yoursite.com/tags/software-installs/"/>
    
  </entry>
  
  <entry>
    <title>Hexo+github 从windows到mac的迁移（小白水平）</title>
    <link href="http://yoursite.com/2019/09/14/software-install/Hexo+github%20%E4%BB%8Ewindows%E5%88%B0mac%E7%9A%84%E8%BF%81%E7%A7%BB%EF%BC%88%E8%B6%85%E8%AF%A6%E7%BB%86%E6%AD%A5%E9%AA%A4%E5%8F%8A%E9%81%87%E5%88%B0%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%EF%BC%89/"/>
    <id>http://yoursite.com/2019/09/14/software-install/Hexo+github 从windows到mac的迁移（超详细步骤及遇到问题解决）/</id>
    <published>2019-09-14T13:55:27.000Z</published>
    <updated>2019-09-14T12:19:50.953Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>2019的年5月在惠普笔记本搭建了个hexo+github版人博客就；<br>2019的6月刚入手了一个mac，于是乎各种东西都得由windows转移到mac;<br>hexo的搬家路：windows - &gt; MacBook Pro </p><h2 id="总体思路"><a href="#总体思路" class="headerlink" title="总体思路"></a>总体思路</h2><p>自己也算是摸爬滚打搭建迁移成功，把完整步骤分享给大家，同时最后有一些参考链接，如果我的步骤有问题，大家可以参考其他人的.</p><p>理清思路真不难，<strong>过程要细心、耐心</strong>，大概分为以下三个模块：</p><ul><li>首先在mac电脑上安装好<code>hexo</code>，并初始化根目录;</li><li>然后生成新的<code>SSH key</code>，并将其添加到<code>github</code>上;</li><li>将旧电脑中的三个文件，直接粘贴覆盖在新电脑对应的目录。</li></ul><h2 id="言归正传"><a href="#言归正传" class="headerlink" title="言归正传"></a>言归正传</h2><h2 id="一-安装hexo前奏"><a href="#一-安装hexo前奏" class="headerlink" title="一. 安装hexo前奏"></a>一. 安装hexo前奏</h2><h3 id="1-安装Homebrew（下载速度有点慢，耐心-）"><a href="#1-安装Homebrew（下载速度有点慢，耐心-）" class="headerlink" title="1. 安装Homebrew（下载速度有点慢，耐心~~）"></a>1. 安装Homebrew（下载速度有点慢，耐心~~）</h3><p>Homebrew安装过程很简单，直接打开mac电脑的<strong>Terminal</strong>命令窗口，把下面的代码粘贴一下，按回车键执行即可，安装过程中两次停顿，分别需要输入 y 和 电脑密码</p><table><tr><td bgcolor="black"> <font size="3" color="white">/usr/bin/ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)" </font></td></tr></table>  <p>查看安装是否成功命令：</p><table><tr><td bgcolor="black"> <font size="3" color="white"> brew --version </font></td></tr></table>  <p>安装成功提示版本号，如下图</p><p><img src="https://github.com/HuanwenW/MyPostImag/blob/master/190912-mac/Homebrewsuccessful.jpg?raw=true" alt="Homebrew安装成功！"><span class="img-alt">Homebrew安装成功！</span></p><h3 id="2-安装git"><a href="#2-安装git" class="headerlink" title="2. 安装git"></a>2. 安装git</h3><p>先检查下电脑是否已存在Git，若mac自带git，此步可以跳过，查看命令如下</p><table><tr><td bgcolor="black"> <font size="3" color="white"> git --version </font></td></tr></table>  <p>若不存在，使用brew安装Git，安装命令如下</p><table><tr><td bgcolor="black"> <font size="3" color="white"> brew install git </font></td></tr></table>  <p>同样，输入<strong>git –version</strong> 验证是否安装成功</p><p>安装成功提示版本号，如下图</p><p><img src="https://github.com/HuanwenW/MyPostImag/blob/master/190912-mac/gitSuccessful.jpg?raw=true" alt="git安装成功！"><span class="img-alt">git安装成功！</span></p><h3 id="3-安装node"><a href="#3-安装node" class="headerlink" title="3. 安装node"></a>3. 安装node</h3><p>输入命令如下</p><table><tr><td bgcolor="black"> <font size="3" color="white"> brew install node </font></td></tr></table> <p>检查安装是否成功，一定要安装成功，否者否许操作中会报错</p><table><tr><td bgcolor="black"> <font size="3" color="white"> node --version </font></td></tr></table> <p>安装成功提示版本号，如下图</p><p><img src="https://github.com/HuanwenW/MyPostImag/blob/master/190912-mac/nodeSuccessful.jpg?raw=true" alt="node安装成功！"><span class="img-alt">node安装成功！</span></p><h2 id="二-Hexo的安装及初始化"><a href="#二-Hexo的安装及初始化" class="headerlink" title="二. Hexo的安装及初始化"></a>二. Hexo的安装及初始化</h2><h3 id="1-用-node-的-npm-安装-hexo，命令如下（下载速度有点慢，耐心-）"><a href="#1-用-node-的-npm-安装-hexo，命令如下（下载速度有点慢，耐心-）" class="headerlink" title="1. 用 node 的 npm 安装 hexo，命令如下（下载速度有点慢，耐心~~）"></a>1. 用 node 的 npm 安装 hexo，命令如下（下载速度有点慢，耐心~~）</h3><table><tr><td bgcolor="black"> <font size="3" color="white"> sudo npm install --unsafe-perm=true -g hexo-cli </font></td></tr></table> <h3 id="2-初始化hexo"><a href="#2-初始化hexo" class="headerlink" title="2. 初始化hexo"></a>2. 初始化hexo</h3><p>创建HexoBlog（名字根据个人喜好自取）文件夹,输入下面命令：    </p><table><tr><td bgcolor="black"> <font size="3" color="white"> hexo init HexoBlog  </font></td></tr></table>  <p><strong>！！！报错提示及解决方案</strong></p><p><img src="https://github.com/HuanwenW/MyPostImag/blob/master/190912-mac/hexo%20erro.jpg?raw=true" alt="创建HexoBlog报错"><span class="img-alt">创建HexoBlog报错</span></p><p><img src="https://github.com/HuanwenW/MyPostImag/blob/master/190912-mac/hexo%20ok.jpg?raw=true" alt="npm权限问题解决方案"><span class="img-alt">npm权限问题解决方案</span></p><h3 id="3-体验hexo魅力"><a href="#3-体验hexo魅力" class="headerlink" title="3. 体验hexo魅力"></a>3. 体验hexo魅力</h3><p>​       由于初始化hexo 之后source目录下自带一篇hello world文章, 所以依次执行下方两个命令：<br><font color="#DC143C" size="3">&ensp;注意：执行下面命令前要先进入blog文件夹中重新打开git命令窗口！！！</font>  </p><table><tr><td bgcolor="black"> <font size="3" color="white">$ hexo generate </font></td></tr></table>  <p> 命令含义： 生成静态文件，等价于(可简写为)： <code>hexo  g</code>    </p><table><tr><td bgcolor="black"> <font size="3" color="white">$ hexo server  </font></td></tr></table>  <p> 命令含义： 启动本地服务器，等价于(可简写为)： <code>hexo  s</code></p><p>打开浏览器，输入网址： <a href="http://localhost:4000/" target="_blank" rel="noopener">http://localhost:4000/</a> ，即可看到网站初步的模样。<br><img src="https://github.com/HuanwenW/MyPostImag/blob/master/190410-boke/github-2.png?raw=true" alt="bendibokeliulan"><span class="img-alt">bendibokeliulan</span></p><h2 id="三-mac生成SSH及配置"><a href="#三-mac生成SSH及配置" class="headerlink" title="三. mac生成SSH及配置"></a>三. mac生成SSH及配置</h2><h3 id="1-先检查一下本机的-SSH-key是否已存在"><a href="#1-先检查一下本机的-SSH-key是否已存在" class="headerlink" title="1. 先检查一下本机的 SSH key是否已存在"></a>1. 先检查一下本机的 SSH key是否已存在</h3><table><tr><td bgcolor="black"> <font size="3" color="white">ls -a ~/.ssh  </font></td></tr></table><h3 id="2-若不存在，输入以下命令，生成ssh"><a href="#2-若不存在，输入以下命令，生成ssh" class="headerlink" title="2. 若不存在，输入以下命令，生成ssh"></a>2. 若不存在，输入以下命令，生成ssh</h3><table><tr><td bgcolor="black"> <font size="3" color="white">ssh -T git@github.com  </font></td></tr></table><p><img src="https://github.com/HuanwenW/MyPostImag/blob/master/190912-mac/ssh%20open%202.jpg?raw=true" alt="生成ssh"><span class="img-alt">生成ssh</span></p><h3 id="3-你可能找不命令窗口提示所生成的ssh在哪里，此时可直接用命令打开-ssh文件"><a href="#3-你可能找不命令窗口提示所生成的ssh在哪里，此时可直接用命令打开-ssh文件" class="headerlink" title="3. 你可能找不命令窗口提示所生成的ssh在哪里，此时可直接用命令打开.ssh文件"></a>3. 你可能找不命令窗口提示所生成的ssh在哪里，此时可直接用命令打开.ssh文件</h3><table><tr><td bgcolor="black"> <font size="3" color="white">open ~/.ssh </font></td></tr></table><h3 id="4-复制id-rsa-pub里面的所有内容"><a href="#4-复制id-rsa-pub里面的所有内容" class="headerlink" title="4. 复制id_rsa.pub里面的所有内容"></a>4. 复制id_rsa.pub里面的所有内容</h3><ul><li><p>手动打开id_rsa.pub文件，复制里面的所有内容</p></li><li><p>直接在终端打开文件，复制生成内容，打开文件命令如下</p></li></ul><table><tr><td bgcolor="black"> <font size="3" color="white">cat ~/.ssh/id_rsa.pub </font></td></tr></table><h3 id="5-进入github配置ssh"><a href="#5-进入github配置ssh" class="headerlink" title="5. 进入github配置ssh"></a>5. 进入github配置ssh</h3><p>然后进入进入自己的github页面，找到setting下的SSH：<a href="https://github.com/settings/ssh" target="_blank" rel="noopener">链接</a>  </p><p>依次执行下面步骤：点击 New SSH key —— Title：blog —— Key：输入刚才复制的内容 —— Add SSH key  </p><p><img src="https://github.com/HuanwenW/MyPostImag/blob/master/190912-mac/addSSH.jpg?raw=true" alt="添加ssh的配置"><span class="img-alt">添加ssh的配置</span></p><p><strong>d.</strong> 测试一下是否成功,输入下方命令：  </p><table><tr><td bgcolor="black"> <font size="3" color="white">$ ssh -T git@github.com   //Github的注册邮箱地址 </font></td></tr></table>  <p><img src="https://github.com/HuanwenW/MyPostImag/blob/master/190410-boke/github-3.png?raw=true" alt><br>&ensp;&ensp;&ensp;看到上面信息说明SSH已配置成功！  </p><h2 id="四-替换-config-yml-、thems、source-文件"><a href="#四-替换-config-yml-、thems、source-文件" class="headerlink" title="四. 替换_config.yml 、thems、source 文件"></a>四. 替换_config.yml 、thems、source 文件</h2><p>从<strong>windows</strong>电脑中复制_config.yml 、thems、source三个文件 ，替换<strong>mac</strong>下的_config.yml 、thems、source 三个文件，即可完成原主题的迁移</p><h2 id="五-主题相关设置专题"><a href="#五-主题相关设置专题" class="headerlink" title="五. 主题相关设置专题"></a>五. 主题相关设置专题</h2><p>此处不在啰嗦，完全参照<a href="https://github.com/Youthink/hexo-themes-yearn/wiki/主题使用教程-📖" target="_blank" rel="noopener">hexo搭建模版参照教程</a>的讲解</p><p>也可以参考我的<a href="https://huanwenw.github.io/2019/04/10/hexo-gitHub/" target="_blank" rel="noopener">window版本搭建hexo</a>中第四部分<strong>如何将github和hexo联系起来？</strong>的详细说明</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol><li><a href="[http://gjincai.github.io/2017/01/13/hexo-%E4%BB%8E-windows-%E8%BD%AC%E7%A7%BB%E8%87%B3-Mac/](http://gjincai.github.io/2017/01/13/hexo-从-windows-转移至-Mac/)">hexo从windows转移至Mac</a></li><li><a href="https://hankliu62.github.io/2017/09/09/hexo-github-blog-guide/" target="_blank" rel="noopener">MAC搭建个人博客hexo+github详细完整步骤</a></li><li><a href="https://blog.csdn.net/xy371661665/article/details/77528132" target="_blank" rel="noopener">Mac系统下安装和卸载HomeBrew的方法</a></li><li><a href="https://blog.csdn.net/qq_41234116/article/details/79366454" target="_blank" rel="noopener">Mac安装，简单使用，卸载homebrew详细教程</a></li><li><a href="https://blog.csdn.net/qq_39153421/article/details/89362432" target="_blank" rel="noopener">解决hexo -d 报错问题</a></li><li><a href="https://www.jianshu.com/p/60b3d5584afe" target="_blank" rel="noopener">npm权限问题</a></li><li><a href="https://www.jianshu.com/p/e72e94952d76" target="_blank" rel="noopener">mac下 ssh key 的获取</a></li><li><a href="https://github.com/Youthink/hexo-themes-yearn/wiki/主题使用教程-📖" target="_blank" rel="noopener">hexo搭建模版参照教程</a></li><li><a href="https://github.com/adrai/flowchart.js" target="_blank" rel="noopener">用<strong>flowchart.js</strong>画流程图</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;2019的年5月在惠普笔记本搭建了个hexo+github版人博客就；&lt;br&gt;2019的6月刚入手了一个mac，于是乎各种东西都得由wind
      
    
    </summary>
    
    
      <category term="技术篇" scheme="http://yoursite.com/categories/%E6%8A%80%E6%9C%AF%E7%AF%87/"/>
    
    
      <category term="软件安装" scheme="http://yoursite.com/tags/%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/"/>
    
  </entry>
  
  <entry>
    <title>ubantu系统中的anaconda3下安装anaconda2</title>
    <link href="http://yoursite.com/2019/09/14/software-install/Annaconda3withAnaconda2/"/>
    <id>http://yoursite.com/2019/09/14/software-install/Annaconda3withAnaconda2/</id>
    <published>2019-09-14T13:55:27.000Z</published>
    <updated>2019-09-19T12:42:01.626Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>ubantu系统已经安装有anaconda3，但是要跑的实验使用的是python2.7，需要更换为anaconda2的环境</p><p><strong>注意：anaconda3下对应python3以上的版本，且无法降级python版本！</strong></p><h2 id="具体实现步骤"><a href="#具体实现步骤" class="headerlink" title="具体实现步骤"></a>具体实现步骤</h2><h2 id="1-下载anaconda2系列的安装包"><a href="#1-下载anaconda2系列的安装包" class="headerlink" title="1. 下载anaconda2系列的安装包"></a>1. 下载anaconda2系列的安装包</h2><p>​        <a href="https://repo.continuum.io/archive/" target="_blank" rel="noopener">下载地址</a> （我下载的：  Anaconda2-5.0.1-Linux-x86_64.sh）</p><h2 id="2-在软件所在位置的文件夹内打开终端"><a href="#2-在软件所在位置的文件夹内打开终端" class="headerlink" title="2. 在软件所在位置的文件夹内打开终端"></a>2. <strong>在软件所在位置的文件夹内打开终端</strong></h2><p>Terminal窗口切换到刚刚下载好的（Anaconda2-5.0.1-Linux-x86_64.sh）所在位置</p><h2 id="3-逐条执行以下9条命令-报错可能是权限问题，前面加sudo"><a href="#3-逐条执行以下9条命令-报错可能是权限问题，前面加sudo" class="headerlink" title="3. 逐条执行以下9条命令(报错可能是权限问题，前面加sudo)**"></a>3. <strong>逐条执行以下9条命令</strong>(报错可能是权限问题，前面加sudo)**</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bash Anaconda2-5.0.1-Linux-x86_64.sh -b -p $ HOME/anaconda3/envs/py2</span><br></pre></td></tr></table></figure><p>其中，Anaconda2-5.0.1-Linux-x86_64.sh为所下载的anaconda2软件名，如果不一致需要替换；py2 为环境名称) </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ rm -f $ HOME/anaconda3/envs/py2/bin/conda* </span><br><span class="line">$ rm -f $ HOME/anaconda3/envs/py2/conda-meta/conda-*</span><br><span class="line">$ rm -f $ HOME/anaconda3/envs/py2/bin/activate</span><br><span class="line">$ rm -f $ HOME/anaconda3/envs/py2/bin/deactivate</span><br><span class="line">$ cd $ HOME/anaconda3/envs/py2/bin</span><br><span class="line">$ ln -s ../../../bin/conda.</span><br><span class="line">$ ln -s ../../../bin/activate.</span><br><span class="line">$ ln -s ../../../bin/deactivate.</span><br></pre></td></tr></table></figure><h2 id="4-通过命令switch-python来查看当前Python的版本"><a href="#4-通过命令switch-python来查看当前Python的版本" class="headerlink" title="4. 通过命令switch python来查看当前Python的版本"></a>4. 通过命令switch python来查看当前Python的版本</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">switch python</span><br></pre></td></tr></table></figure><h2 id="5-通过命令source-activate-py2-来激活anaconda2的环境"><a href="#5-通过命令source-activate-py2-来激活anaconda2的环境" class="headerlink" title="5.通过命令source activate py2 来激活anaconda2的环境"></a>5.通过命令source activate py2 来激活anaconda2的环境</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source activate py2</span><br></pre></td></tr></table></figure><h2 id="6-通过命令source-deactivate-py2来返回anaconda3的环境"><a href="#6-通过命令source-deactivate-py2来返回anaconda3的环境" class="headerlink" title="6. 通过命令source deactivate py2来返回anaconda3的环境"></a>6. 通过命令source deactivate py2来返回anaconda3的环境</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source deactivate py2</span><br></pre></td></tr></table></figure><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://github.com/maquanyu/Sunflower-Collection/blob/master/anaconda2和anaconda3共存" target="_blank" rel="noopener">anaconda3下安装anaconda2</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;ubantu系统已经安装有anaconda3，但是要跑的实验使用的是python2.7，需要更换为anaconda2的环境&lt;/p&gt;
&lt;p&gt;&lt;
      
    
    </summary>
    
    
      <category term="装机篇" scheme="http://yoursite.com/categories/%E8%A3%85%E6%9C%BA%E7%AF%87/"/>
    
    
      <category term="software install" scheme="http://yoursite.com/tags/software-install/"/>
    
  </entry>
  
  <entry>
    <title>ubantu 虚拟环境创建</title>
    <link href="http://yoursite.com/2019/09/14/software-install/Create%20a%20virtual%20environment/"/>
    <id>http://yoursite.com/2019/09/14/software-install/Create a virtual environment/</id>
    <published>2019-09-14T12:55:27.000Z</published>
    <updated>2019-09-14T12:45:03.157Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在配置别人的实验环境时，根据作者提供的环境条件逐条安装往往太慢….通常作者会在实验中给requirements.txt文件（里面为实验环境版本配置信息），以下方法介绍如何一次性安装实验所依赖的各种包！</p><h2 id="0-打开Terminal（pycharm下）"><a href="#0-打开Terminal（pycharm下）" class="headerlink" title="0. 打开Terminal（pycharm下）"></a>0. 打开<strong>Terminal</strong>（pycharm下）</h2><p>先在pycharm所打开的项目，下方菜单切换到项目的Terminal中进行，这样就是对当前项目配备环境。</p><h2 id="1-创建虚拟环境"><a href="#1-创建虚拟环境" class="headerlink" title="1.创建虚拟环境"></a>1.创建虚拟环境</h2><table><tr><td bgcolor="black"> <font size="3" color="white"> conda  create  -n  自己虚拟环境的名字 python=3.6（3.6是当前版本号，版本号也可省略） </font></td></tr></table>  <p>执行过程中，需要输入 y</p><h2 id="2-激活虚拟环境–2种方式"><a href="#2-激活虚拟环境–2种方式" class="headerlink" title="2. 激活虚拟环境–2种方式"></a>2. 激活虚拟环境–2种方式</h2><table><tr><td bgcolor="black"> <font size="3" color="white"> source activate + 自己虚拟环境的名字（方法1） </font></td></tr></table>  <table><tr><td bgcolor="black"> <font size="3" color="white"> conda activate + 自己虚拟环境的名字（方法 2） </font></td></tr></table>  <h2 id="3-安装所需环境（一般作者把需要的环境写在requirements-txt中-）"><a href="#3-安装所需环境（一般作者把需要的环境写在requirements-txt中-）" class="headerlink" title="3.安装所需环境（一般作者把需要的环境写在requirements.txt中 ）"></a>3.安装所需环境（一般作者把需要的环境写在requirements.txt中 ）</h2><table><tr><td bgcolor="black"> <font size="3" color="white"> pip install  -r  requirements.txt </font></td></tr></table> <p>即使requirements.txt中所需的环境<strong>已安装也没关系</strong>，系统会自动解决</p><h2 id="4-查看是否安装成功"><a href="#4-查看是否安装成功" class="headerlink" title="4.查看是否安装成功"></a>4.查看是否安装成功</h2><p>打开电脑的Terminals窗口 ，输入以下命令，会显示电脑中所有的虚拟环境，确认刚刚创建的虚拟环境是否包含在里面。</p><table><tr><td bgcolor="black"> <font size="3" color="white"> conda env list </font></td></tr></table> <h2 id="5-配置实验环境"><a href="#5-配置实验环境" class="headerlink" title="5. 配置实验环境"></a>5. 配置实验环境</h2><p>依次点击pycharm下的Project–seeting–add（而不是show all）–切换conda环境–自动检测出刚安装的环境—项目设置</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;在配置别人的实验环境时，根据作者提供的环境条件逐条安装往往太慢….通常作者会在实验中给requirements.txt文件（里面为实验环境版
      
    
    </summary>
    
    
      <category term="技术篇" scheme="http://yoursite.com/categories/%E6%8A%80%E6%9C%AF%E7%AF%87/"/>
    
    
  </entry>
  
  <entry>
    <title>关于转载</title>
    <link href="http://yoursite.com/2019/09/12/software-install/copyright-reprinted/"/>
    <id>http://yoursite.com/2019/09/12/software-install/copyright-reprinted/</id>
    <published>2019-09-12T13:55:27.000Z</published>
    <updated>2019-09-14T03:42:39.387Z</updated>
    
    <content type="html"><![CDATA[<h2 id="我希望的转载方式"><a href="#我希望的转载方式" class="headerlink" title="我希望的转载方式"></a>我希望的转载方式</h2><p><strong>分享链接转载，指向我的博文。</strong> 我觉的这是最好的转载方式，互赢。</p><h2 id="使用别人的原创"><a href="#使用别人的原创" class="headerlink" title="使用别人的原创"></a>使用别人的原创</h2><p>换位思考，以后我使用别人的图片和摘选的内容时，我会带上来源地址和作者署名，尊重原创</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;我希望的转载方式&quot;&gt;&lt;a href=&quot;#我希望的转载方式&quot; class=&quot;headerlink&quot; title=&quot;我希望的转载方式&quot;&gt;&lt;/a&gt;我希望的转载方式&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;分享链接转载，指向我的博文。&lt;/strong&gt; 我觉的这是最好的转载方式，互
      
    
    </summary>
    
    
      <category term="版权声明" scheme="http://yoursite.com/categories/%E7%89%88%E6%9D%83%E5%A3%B0%E6%98%8E/"/>
    
    
      <category term="软件安装" scheme="http://yoursite.com/tags/%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/"/>
    
  </entry>
  
  <entry>
    <title>MacBook Pro 识别希捷移动硬盘</title>
    <link href="http://yoursite.com/2019/09/12/software-install/mac+xijieHarddisk/"/>
    <id>http://yoursite.com/2019/09/12/software-install/mac+xijieHarddisk/</id>
    <published>2019-09-12T07:55:27.000Z</published>
    <updated>2019-09-14T08:33:11.005Z</updated>
    
    <content type="html"><![CDATA[<p>内心OS：被困扰18个小时的question，终于解决，只因思路不清晰，走了很多弯路，太蠢！–20190912</p><p><strong>悟！</strong>：很多博客只是针对自己电脑遇到的问题给出解决方案，官网是针对所有电脑给出的解决方案，而且官网给出的说明更简洁且可靠！</p><h2 id="设备描述"><a href="#设备描述" class="headerlink" title="设备描述"></a>设备描述</h2><ul><li><p>MacBcook Pro -2018 version：10.14.3 </p></li><li><p>希捷硬盘购买信息：希捷(Seagate) 1TB USB3.0 移动硬盘 睿品新版铭 兼容Mac</p></li></ul><h2 id="问题解决步骤"><a href="#问题解决步骤" class="headerlink" title="问题解决步骤"></a>问题解决步骤</h2><ol><li><p><a href="https://www.seagate.com/cn/zh/support/downloads/" target="_blank" rel="noopener">希捷官网</a>下载 Paragon 驱动程序（注意mac版本）</p><p><img src="https://github.com/HuanwenW/MyPostImag/blob/master/190912-mac/0-download%20driver.jpg?raw=true" alt="官网下载界面"><span class="img-alt">官网下载界面</span></p></li><li><p>下载完成后双击软件，按照提示步骤完成安装</p></li><li><p>重启Mac</p></li><li><p>将希捷硬盘插入mac</p></li><li><p>打开 <strong>NTFS for Mac</strong> 软件，发现移动硬盘已显示，操作如下图</p><p><img src="https://github.com/HuanwenW/MyPostImag/blob/master/190912-mac/2-disk%20installation.jpg?raw=true" alt="借助第三方软件安装硬盘"><span class="img-alt">借助第三方软件安装硬盘</span></p></li><li><p>修改移动硬盘名称（若不需要可以直接执行第7步）</p><p><img src="https://github.com/HuanwenW/MyPostImag/blob/master/190912-mac/4-rename.jpg?raw=true" alt="移动硬盘重命名"><span class="img-alt">移动硬盘重命名</span></p></li><li><p>点击 右侧 磁盘名称，即可正常访问磁盘</p><p><img src="https://github.com/HuanwenW/MyPostImag/blob/master/190912-mac/3-disk%20view.jpg?raw=true" alt="访问移动硬盘"><span class="img-alt">访问移动硬盘</span></p></li></ol><h2 id="问题解答"><a href="#问题解答" class="headerlink" title="问题解答"></a>问题解答</h2><ol><li><p>如何修改硬盘名称？</p><p>参见步骤6</p></li></ol><h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><p>1.<a href="https://www.bilibili.com/video/av8611848/" target="_blank" rel="noopener">如何在Mac系统下正确使用硬盘-视频讲解</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;内心OS：被困扰18个小时的question，终于解决，只因思路不清晰，走了很多弯路，太蠢！–20190912&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;悟！&lt;/strong&gt;：很多博客只是针对自己电脑遇到的问题给出解决方案，官网是针对所有电脑给出的解决方案，而且官网给出的说明更简洁且
      
    
    </summary>
    
    
      <category term="技术篇" scheme="http://yoursite.com/categories/%E6%8A%80%E6%9C%AF%E7%AF%87/"/>
    
    
      <category term="软件安装" scheme="http://yoursite.com/tags/%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/"/>
    
  </entry>
  
  <entry>
    <title>Typora（一款比Markdown更好用的软件编辑器）使用方法简介.md</title>
    <link href="http://yoursite.com/2019/09/10/software-install/Typora%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%E7%AE%80%E4%BB%8B/"/>
    <id>http://yoursite.com/2019/09/10/software-install/Typora使用方法简介/</id>
    <published>2019-09-10T13:55:27.000Z</published>
    <updated>2019-09-19T12:18:11.918Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Typora编辑器使用方法–参考博客链接"><a href="#Typora编辑器使用方法–参考博客链接" class="headerlink" title="Typora编辑器使用方法–参考博客链接"></a><a href="https://blog.csdn.net/wirelessqa/article/details/70432631" target="_blank" rel="noopener">Typora编辑器使用方法–参考博客链接</a></h3><p><a href="https://www.cnblogs.com/peizhe123/p/7994746.html" target="_blank" rel="noopener">Mac下使用Typora的一些简单操作</a></p><ol><li>三个 ~ (英文状态下的波浪线) 回车 就可以输入<strong>代码块</strong>,如果想让显示行数，需要开启，在Typora–&gt;偏好设置–&gt;Markdown 设置</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>粗体</strong>、<em>斜体</em>、==高亮==、<del>删除线</del>、<u>下划线</u>、我是^上标^、我是 <del>下标</del>、<a href="http://www.baidu.com" target="_blank" rel="noopener">超链接</a></p><p>  <img src="https://img3.doubanio.com/view/movie_poster_cover/lpst/public/p2411953504.jpg" alt="示例图片"><span class="img-alt">示例图片</span></p><h2 id="无序列表"><a href="#无序列表" class="headerlink" title="无序列表"></a>无序列表</h2><ul><li><p>无序列表1</p></li><li><p>无序列表2</p><h2 id="有序列表"><a href="#有序列表" class="headerlink" title="有序列表"></a>有序列表</h2></li></ul><ol><li><p>有序列表</p></li><li><p>有序列表</p><h2 id="任务列表"><a href="#任务列表" class="headerlink" title="任务列表"></a>任务列表</h2></li></ol><ul><li><input disabled type="checkbox"> <p>看电影</p></li><li><input disabled type="checkbox"> <p>听音乐</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Typora编辑器使用方法–参考博客链接&quot;&gt;&lt;a href=&quot;#Typora编辑器使用方法–参考博客链接&quot; class=&quot;headerlink&quot; title=&quot;Typora编辑器使用方法–参考博客链接&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://blog.csdn
      
    
    </summary>
    
    
      <category term="技术篇" scheme="http://yoursite.com/categories/%E6%8A%80%E6%9C%AF%E7%AF%87/"/>
    
    
      <category term="软件安装" scheme="http://yoursite.com/tags/%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/"/>
    
  </entry>
  
  <entry>
    <title>softwaerVersion</title>
    <link href="http://yoursite.com/2019/05/11/software-install/softwaerVersionInquery/"/>
    <id>http://yoursite.com/2019/05/11/software-install/softwaerVersionInquery/</id>
    <published>2019-05-11T03:57:15.000Z</published>
    <updated>2019-05-11T04:54:50.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Ubantu-系统"><a href="#Ubantu-系统" class="headerlink" title="Ubantu 系统"></a>Ubantu 系统</h2><p>本文为在为Ubantu系统安装tensorflow时，因为已有一些软件的安装，所以需要查看确认下</p><p><strong>首先 快捷键（Ctrl+Alt+t）打开终端</strong></p><h2 id="CUDA"><a href="#CUDA" class="headerlink" title="CUDA"></a>CUDA</h2><blockquote><p>nvcc -V  </p></blockquote><p>！！ 注意 V 是大写</p><h2 id="CUDNN"><a href="#CUDNN" class="headerlink" title="CUDNN"></a>CUDNN</h2><blockquote><p>cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR  </p></blockquote><h2 id="GCC"><a href="#GCC" class="headerlink" title="GCC"></a>GCC</h2><p>gcc -v</p><p>！！ 注意 v 是小写</p><h2 id="Anaconda"><a href="#Anaconda" class="headerlink" title="Anaconda"></a>Anaconda</h2><blockquote><p>conda -V</p></blockquote><p>！！ 注意 V 是大写  </p><h2 id="Ubantu"><a href="#Ubantu" class="headerlink" title="Ubantu"></a>Ubantu</h2><blockquote><ol><li>cat /proc/version  </li><li>uname -a  </li><li>lsb_release -a  </li></ol></blockquote><h2 id="参考博客"><a href="#参考博客" class="headerlink" title="参考博客"></a>参考博客</h2><p>1.<a href="https://medium.com/@changrongko/nv-how-to-check-cuda-and-cudnn-version-e05aa21daf6c" target="_blank" rel="noopener">查看 CUDA cudnn 版本</a>  </p><ol start="2"><li><a href="https://jingyan.baidu.com/article/2c8c281d87c9890009252a41.html" target="_blank" rel="noopener">ubuntu查看gcc的版本</a>   </li><li><a href="https://blog.csdn.net/wyx100/article/details/79453941" target="_blank" rel="noopener">查看Anaconda版本、Anaconda和python版本对应关系和快速下载</a>     </li><li><a href="https://zhidao.baidu.com/question/154707237.html?fr=iks&word=%C8%E7%BA%CE%D3%C3%C3%FC%C1%EE%B2%E9%D1%AF+Ubantu+%B0%E6%B1%BE%BA%C5&ie=gbk" target="_blank" rel="noopener">如何用命令查询 Ubantu 版本号</a>  </li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Ubantu-系统&quot;&gt;&lt;a href=&quot;#Ubantu-系统&quot; class=&quot;headerlink&quot; title=&quot;Ubantu 系统&quot;&gt;&lt;/a&gt;Ubantu 系统&lt;/h2&gt;&lt;p&gt;本文为在为Ubantu系统安装tensorflow时，因为已有一些软件的安装，所以需
      
    
    </summary>
    
    
      <category term="software" scheme="http://yoursite.com/categories/software/"/>
    
    
      <category term="Version" scheme="http://yoursite.com/tags/Version/"/>
    
  </entry>
  
  <entry>
    <title>推荐系统评价--NDCG方法概述</title>
    <link href="http://yoursite.com/2019/05/02/MachineLearning/RSC-NDCG/"/>
    <id>http://yoursite.com/2019/05/02/MachineLearning/RSC-NDCG/</id>
    <published>2019-05-02T07:48:25.000Z</published>
    <updated>2019-05-02T09:14:46.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="NDCG方法概述"><a href="#NDCG方法概述" class="headerlink" title="NDCG方法概述"></a>NDCG方法概述</h2><p><strong>NDCG(Normalized Discounted Cumulative Gain)</strong>：计算相对复杂。对于排在结位置n处的NDCG的计算公式如下图所示：<br><img src="https://github.com/HuanwenW/MyPostImag/blob/master/190502-Res/NDCG.png?raw=true" alt="NDCG公式"><span class="img-alt">NDCG公式</span>  </p><p>&ensp;&ensp;&ensp;一个推荐系统返回一些项并形成一个列表，我们想要计算这个列表有多好。每一项都有一个相关的评分值，通常这些评分值是一个非负数。这就是<strong>gain（增益）</strong>。此外，对于这些没有用户反馈的项，我们通常设置其增益为0。 </p><p><strong>例如：假设有两个主题，主题1有4个相关网页，主题2有5个相关网页。</strong>  </p><p>(1) 相关度分成从0到r的r+1的等级(r可设定)。当取r=5时，等级设定如下图所示：</p><p><img src="https://github.com/HuanwenW/MyPostImag/blob/master/190502-Res/NDCG-gain.png?raw=true" alt="NDCG-增益"><span class="img-alt">NDCG-增益</span><br>(应该还有r=1那一级，原文档有误，不过这里不影响理解)   </p><p>(2) 例如现在有一个query={abc}，返回下图左列的Ranked List(URL)，当假设用户的选择与排序结果无关(即每一级都等概率被选中)，则生成的累计增益值如下图最右列所示：<br><img src="https://github.com/HuanwenW/MyPostImag/blob/master/190502-Res/NDCG-CumulativeGain.png?raw=true" alt="NDCG-累计增益"><span class="img-alt">NDCG-累计增益</span><br>&ensp;&ensp;&ensp;我们把这些分数相加，也就是<strong>Cumulative Gain（累积增益）</strong>。我们更愿意看那些位于列表前面的最相关的项，因此，在把这些分数相加之前，我们将每项除以一个递增的数（通常是该项位置的对数值），也就是折损值，并得到DCG。 </p><p>(3) 考虑到一般情况下用户会优先点选排在前面的搜索结果，所以应该引入一个折算因子(discounting factor): log(2)/log(1+rank)。这时将获得DCG值(Discounted Cumulative Gain)如下如所示：<br><img src="https://github.com/HuanwenW/MyPostImag/blob/master/190502-Res/NDCG-gain.png?raw=true" alt="NDCG-折算因子"><span class="img-alt">NDCG-折算因子</span>    </p><p>(4) &ensp;&ensp;&ensp;在用户与用户之间，DCGs没有直接的可比性，所以我们要对它们进行归一化处理。即为了使不同等级上的搜索结果的得分值容易比较，需要将DCG值归一化的到NDCG值。操作如下图所示，首先计算理想返回结果List的DCG值：<br><img src="https://github.com/HuanwenW/MyPostImag/blob/master/190502-Res/NDCG-Normalized.png?raw=true" alt="NDCG-归一化"><span class="img-alt">NDCG-归一化</span>  </p><p>(5) 然后用DCG/MaxDCG就得到NDCG值，如下图所示：<br><img src="https://github.com/HuanwenW/MyPostImag/blob/master/190502-Res/NDCG-gain.png?raw=true" alt="NDCG-比值"><span class="img-alt">NDCG-比值</span>    </p><p>&ensp;&ensp;&ensp; 最糟糕的情况是，当使用非负相关评分时DCG为0。为了得到最好的，我们把测试集中所有的条目置放在理想的次序下，采取的是前K项并计算它们的DCG。然后将原DCG除以理想状态下的DCG并得到<strong>NDCG@K</strong>，它是一个0到1之间的数。<br>&ensp;&ensp;&ensp;你可能已经注意到，我们使用K表示推荐列表的长度。这个数由专业人员指定。你可以把它想像成是一个用户可能会注意到的多少个项的一个估计值，如10或50这些比较常见的值。</p><h2 id="参考博客"><a href="#参考博客" class="headerlink" title="参考博客"></a>参考博客</h2><ol><li><a href="https://blog.csdn.net/u010670689/article/details/73196054" target="_blank" rel="noopener"><strong>推荐系统评价：NDCG方法概述</strong></a>  </li><li><a href="https://blog.csdn.net/lujiandong1/article/details/77123805" target="_blank" rel="noopener">NDCG及其实现</a>  </li><li><a href="https://blog.csdn.net/weixin_38405636/article/details/80675312" target="_blank" rel="noopener">排序算法常用评价指标计算方式（AUC,MAP,NDCG,MRR）</a>  </li><li><a href="https://www.cnblogs.com/eyeszjwang/articles/2368087.html" target="_blank" rel="noopener"><strong>Learning to Rank for IR的评价指标—MAP,NDCG,MRR</strong></a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;NDCG方法概述&quot;&gt;&lt;a href=&quot;#NDCG方法概述&quot; class=&quot;headerlink&quot; title=&quot;NDCG方法概述&quot;&gt;&lt;/a&gt;NDCG方法概述&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;NDCG(Normalized Discounted Cumulative 
      
    
    </summary>
    
    
      <category term="Res" scheme="http://yoursite.com/categories/Res/"/>
    
    
      <category term="推荐系统" scheme="http://yoursite.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>Welcome to NLP-2019-huanhuan-homework-11</title>
    <link href="http://yoursite.com/2019/04/27/NLP/NLP-RNN-11/"/>
    <id>http://yoursite.com/2019/04/27/NLP/NLP-RNN-11/</id>
    <published>2019-04-27T12:00:57.000Z</published>
    <updated>2019-04-27T12:44:06.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="内容涵盖"><a href="#内容涵盖" class="headerlink" title="内容涵盖"></a>内容涵盖</h2><ul><li>RNN的结构。循环神经网络的提出背景、优缺点。着重学习RNN的反向传播、RNN出现的问题（梯度问题、长期依赖问题）、BPTT算法。</li><li>双向RNN</li><li>LSTM、GRU的结构、提出背景、优缺点。</li><li>针对梯度消失（LSTM等其他门控RNN）、梯度爆炸（梯度截断）的解决方案。</li><li>Text-RNN的原理。</li><li>利用Text-RNN模型来进行文本分类。<h2 id="RNN-基础"><a href="#RNN-基础" class="headerlink" title="RNN 基础"></a>RNN 基础</h2>&ensp;&ensp;&ensp;RNN（Recurrent Neural Network）是一类用于处理序列数据的神经网络。首先我们要明确什么是序列数据，摘取百度百科词条：时间序列数据是指在不同时间点上收集到的数据，这类数据反映了某一事物、现象等随时间的变化状态或程度。这是时间序列数据的定义，当然这里也可以不是时间，比如文字序列，但总归序列数据有一个特点——后面的数据跟前面的数据有关系。  </li></ul><p><strong>(1)  RNN的结构及变体</strong><br>&ensp;&ensp;&ensp;我们从基础的神经网络中知道，神经网络包含输入层、隐层、输出层，通过激活函数控制输出，层与层之间通过权值连接。激活函数是事先确定好的，那么神经网络模型通过训练“学“到的东西就蕴含在“权值“中。<br>&ensp;&ensp;&ensp;基础的神经网络只在层与层之间建立了权连接，RNN最大的不同之处就是在层之间的神经元之间也建立的权连接。如图<br><img src="https://github.com/HuanwenW/MyPostImag/blob/master/190408-NLP-gainian/RNN-1.png?raw=true" alt="Rnn"><span class="img-alt">Rnn</span>  </p><p>&ensp;&ensp;&ensp;这是一个标准的RNN结构图，图中每个箭头代表做一次变换，也就是说箭头连接带有权值。左侧是折叠起来的样子，右侧是展开的样子，左侧中h旁边的箭头代表此结构中的“循环“体现在隐层。<br>在展开结构中我们可以观察到，在标准的RNN结构中，隐层的神经元之间也是带有权值的。也就是说，随着序列的不断推进，前面的隐层将会影响后面的隐层。图中O代表输出，y代表样本给出的确定值，L代表损失函数，我们可以看到，“损失“也是随着序列的推荐而不断积累的。<br>除上述特点之外，标准RNN的还有以下特点：<br>1、权值共享，图中的W全是相同的，U和V也一样。<br>2、每一个输入值都只与它本身的那条路线建立权连接，不会和别的神经元连接。  </p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://www.atyun.com/30234.html" target="_blank" rel="noopener">一份详细的LSTM和GRU图解</a>  </li><li><a href="https://zhuanlan.zhihu.com/p/37070414" target="_blank" rel="noopener">Tensorflow实战(1): 实现深层循环神经网络</a>  </li><li><a href="https://x-algo.cn/index.php/2017/01/13/1609/" target="_blank" rel="noopener">从LSTM到Seq2Seq-大数据算法</a></li><li><a href="https://github.com/airalcorn2/Recurrent-Convolutional-Neural-Network-Text-Classifier" target="_blank" rel="noopener">GitHub - airalcorn2/Recurrent-Convolutional-Neural…</a>  </li><li><a href="https://github.com/zhangfazhan/TextRCNN" target="_blank" rel="noopener">GitHub - zhangfazhan/TextRCNN: TextRCNN 文本分类</a>  </li><li><a href="https://github.com/roomylee/rcnn-text-classification" target="_blank" rel="noopener">RCNN tf (推荐)</a>  </li><li><a href="https://blog.csdn.net/zhaojc1995/article/details/80572098" target="_blank" rel="noopener">RNN</a>  </li><li><a href="https://blog.csdn.net/heyongluoyao8/article/details/48636251" target="_blank" rel="noopener">循环神经网络(RNN, Recurrent Neural Networks)介绍</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;内容涵盖&quot;&gt;&lt;a href=&quot;#内容涵盖&quot; class=&quot;headerlink&quot; title=&quot;内容涵盖&quot;&gt;&lt;/a&gt;内容涵盖&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;RNN的结构。循环神经网络的提出背景、优缺点。着重学习RNN的反向传播、RNN出现的问题（梯度问题、长期依赖问题
      
    
    </summary>
    
    
      <category term="NLP" scheme="http://yoursite.com/categories/NLP/"/>
    
    
      <category term="RNN" scheme="http://yoursite.com/tags/RNN/"/>
    
  </entry>
  
  <entry>
    <title>Welcome to NLP-2019-huanhuan-homework-10</title>
    <link href="http://yoursite.com/2019/04/25/NLP/NLP-juanjishenjingwangluo-10/"/>
    <id>http://yoursite.com/2019/04/25/NLP/NLP-juanjishenjingwangluo-10/</id>
    <published>2019-04-25T08:00:35.000Z</published>
    <updated>2019-04-25T09:53:32.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="内容涵盖"><a href="#内容涵盖" class="headerlink" title="内容涵盖"></a>内容涵盖</h2><ul><li>卷积运算的定义、动机（稀疏权重、参数共享、等变表示）。一维卷积运算和二维卷积运算</li><li>反卷积(tf.nn.conv2d_transpose)</li><li>池化运算的定义、种类（最大池化、平均池化等）、动机</li><li>Text-CNN的原理</li><li>利用Text-CNN模型来进行文本分类  </li></ul><h2 id="1-卷积运算的定义、动机"><a href="#1-卷积运算的定义、动机" class="headerlink" title="1. 卷积运算的定义、动机"></a>1. 卷积运算的定义、动机</h2><p>&ensp;&ensp;&ensp;卷积网络也叫做卷积神经网络，是一种专门用来处理类似具有网格结构的数据的神经网络。例如时间序列数据（可以认为在时间轴上有规律的一维网格数据）、图像数据（可以认为二维的像素网格数据）。卷积神经网络在许多应用中发挥着巨大的作用，比如图像领域。卷积是一种特殊的线性运算，是对两个实值函数的一种数学运算，卷积运算通常用符号 * 来表示。卷积网络是指那些至少在网络的一层中使用卷积运算来代替一般的矩阵乘法运算的神经网络。</p><p>&ensp;&ensp;&ensp;卷积运算运用三个重要的思想来帮助改进机器学习系统 ：稀疏交互（sparse interactions)、参数共享（parameter sharing）、等变表示（equivariant pepresentations).</p><h3 id="1-卷积运算"><a href="#1-卷积运算" class="headerlink" title="(1)卷积运算"></a>(1)卷积运算</h3><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>1.<a href="https://zhuanlan.zhihu.com/p/57575810" target="_blank" rel="noopener"><strong>卷积有多少种？</strong>一文读懂深度学习中的各种卷积</a><br>2.<a href="https://blog.csdn.net/yinkun6514/article/details/79281278" target="_blank" rel="noopener">卷积网络笔记</a><br>3.<a href="https://blog.csdn.net/AdamShan/article/details/79193775" target="_blank" rel="noopener">卷积神经网络入门，基于深度学习的车辆实时检测</a><br>4.<a href="https://blog.csdn.net/weixin_33774883/article/details/86942408" target="_blank" rel="noopener">卷积网络——动机</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;内容涵盖&quot;&gt;&lt;a href=&quot;#内容涵盖&quot; class=&quot;headerlink&quot; title=&quot;内容涵盖&quot;&gt;&lt;/a&gt;内容涵盖&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;卷积运算的定义、动机（稀疏权重、参数共享、等变表示）。一维卷积运算和二维卷积运算&lt;/li&gt;
&lt;li&gt;反卷积(tf
      
    
    </summary>
    
    
      <category term="NLP" scheme="http://yoursite.com/categories/NLP/"/>
    
    
      <category term="卷积神经网络基础" scheme="http://yoursite.com/tags/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>Welcome to NLP-2019-huanhuan-homework-9</title>
    <link href="http://yoursite.com/2019/04/23/NLP/NLP-jiandanshenjingwangluo-9/"/>
    <id>http://yoursite.com/2019/04/23/NLP/NLP-jiandanshenjingwangluo-9/</id>
    <published>2019-04-23T13:34:24.000Z</published>
    <updated>2019-04-23T14:24:20.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="内容涵盖"><a href="#内容涵盖" class="headerlink" title="内容涵盖"></a>内容涵盖</h2><ul><li>文本表示：从one-hot到word2vec。  </li><li>词袋模型：离散、高维、稀疏。  </li><li>分布式表示：连续、低维、稠密。word2vec词向量原理并实践，用来表示文本。  </li></ul><h2 id="1-文本表示"><a href="#1-文本表示" class="headerlink" title="1.文本表示"></a>1.文本表示</h2><p>&ensp;&ensp;&ensp;词向量的意思就是通过一个数字组成的向量来表示一个词，这个向量的构成有很多种方法，如one-hot编码、基于共现矩阵的方式、word2vec、动态词向量ELMo等。  </p><p><strong>(1)one-hot编码</strong><br>&ensp;&ensp;&ensp;one-hot编码又称独热编码、一位有效编码。其方法是使用N位状态寄存器来对N个状态进行编码，每个状态都有它独立的寄存器位，并且在任意时候，其中只有一位有效。<br>假设在一个语料集合中，一共有n个不同的词，则可以使用一个长度为n的向量，对于第i个词（i=0….n-1）,向量index=i处的值为1外，向量其他位置的值都为0，这样就可以唯一的通过[0,0,0,1….0,0]形式的向量表示一个词。one-hot向量比较简单也容易理解，但是有很多问题。比如，加入新词时，整个向量的长度会改变，并且存在维数过高难以计算的问题，以及向量的表示方法很难体现两个词之间的关系，因此一般情况下one-hot向量较少使用。<br><strong>优势：</strong>简单易懂<br><strong>不足：</strong> 维度灾难、词汇鸿沟（向量之间都是孤立的）  </p><p><strong>（2）基于贡献矩阵的方式</strong>    </p><p><img src="https://github.com/HuanwenW/MyPostImag/blob/master/190408-NLP-gainian/gongxiangjuzheng.png?raw=true" alt="gongxiangjuzheng"><span class="img-alt">gongxiangjuzheng</span>  </p><p><img src="https://github.com/HuanwenW/MyPostImag/blob/master/190408-NLP-gainian/gongxiangjuzheng-1.png?raw=true" alt="juli"><span class="img-alt">juli</span></p><p>上述矩阵是一个n*n的对称矩阵X，矩阵维数随着词典数量n的增大而增大，可以使用奇异值分解SVD将矩阵维度降低。但是仍存在问题：</p><ol><li>矩阵X的维度经常改</li><li>由于大部分词并不共现而导致的稀疏性</li><li>矩阵维度过高带来的高计算复杂度</li></ol><p><strong>（3）基于神经网络的方式（world embedding）：world2vec</strong><br>&ensp;&ensp;&ensp;Embedding层（输入层到隐藏层）是以one hot为输入、中间层节点数为词向量维数的全连接层，这个全连接层的参数就是我们要获取的词向量表！  </p><h2 id="2-词袋模型：离散、高维、稀疏。"><a href="#2-词袋模型：离散、高维、稀疏。" class="headerlink" title="2. 词袋模型：离散、高维、稀疏。"></a>2. 词袋模型：离散、高维、稀疏。</h2><h2 id="参考博客"><a href="#参考博客" class="headerlink" title="参考博客"></a>参考博客</h2><ol start="0"><li><a href="https://blog.csdn.net/weixin_38493025/article/details/85245044" target="_blank" rel="noopener">词向量（从one-hot到word2vec）</a></li><li><a href="https://blog.csdn.net/itplus/article/details/37969519" target="_blank" rel="noopener">word2vec 中的数学原理详解</a>    </li><li><a href="http://www.hankcs.com/nlp/word2vec.html" target="_blank" rel="noopener">word2vec原理推导与代码分析</a>  </li><li><a href="https://github.com/facebookresearch/fastText#building-fasttext-for-python" target="_blank" rel="noopener">word2vec3：word2vec中的数学原理详解（四）基于 Hierarchical Softmax 的模型</a>  </li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;内容涵盖&quot;&gt;&lt;a href=&quot;#内容涵盖&quot; class=&quot;headerlink&quot; title=&quot;内容涵盖&quot;&gt;&lt;/a&gt;内容涵盖&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;文本表示：从one-hot到word2vec。  &lt;/li&gt;
&lt;li&gt;词袋模型：离散、高维、稀疏。  &lt;/li&gt;
      
    
    </summary>
    
    
      <category term="NLP" scheme="http://yoursite.com/categories/NLP/"/>
    
    
      <category term="简单神经网络" scheme="http://yoursite.com/tags/%E7%AE%80%E5%8D%95%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Welcome to NLP-2019-huanhuan-homework-8</title>
    <link href="http://yoursite.com/2019/04/21/NLP/NLP-shenjingwangluojichu-8/"/>
    <id>http://yoursite.com/2019/04/21/NLP/NLP-shenjingwangluojichu-8/</id>
    <published>2019-04-21T10:52:33.000Z</published>
    <updated>2019-04-21T12:25:24.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="内容涵盖"><a href="#内容涵盖" class="headerlink" title="内容涵盖"></a>内容涵盖</h2><ul><li>前馈神经网络、网络层数、输入层、隐藏层、输出层、隐藏单元、激活函数的概念。</li><li>感知机相关；利用tensorflow等工具定义简单的几层网络（激活函数sigmoid），递归使用链式法则来实现反向传播。</li><li>激活函数的种类以及各自的提出背景、优缺点。（和线性模型对比，线性模型的局限性，去线性化）</li><li>深度学习中的正则化（参数范数惩罚：L1正则化、L2正则化；数据集增强；噪声添加；early stop；Dropout层）、正则化的介绍。</li><li>深度模型中的优化：参数初始化策略；自适应学习率算法（梯度下降、AdaGrad、RMSProp、Adam；优化算法的选择）；batch norm层（提出背景、解决什么问题、层在训练和测试阶段的计算公式）；layer norm层。  </li></ul><h2 id="1-神经网络基础概念"><a href="#1-神经网络基础概念" class="headerlink" title="1. 神经网络基础概念"></a>1. 神经网络基础概念</h2><p>&ensp;&ensp;&ensp; 神经网络是机器学习中的一种模型，是一种模仿动物神经网络行为特征，进行分布式并行信息处理的算法数学模型。神经网络最开始是受生物神经系统的启发，为了模拟生物神经系统而出现的。生物神经系统中最基本的计算单元是神经元。<br><img src="https://github.com/HuanwenW/MyPostImag/blob/master/190408-NLP-gainian/shenjingwangluo-0.jpg?raw=true" alt="shengwu"><span class="img-alt">shengwu</span>  </p><h3 id="1-1-神经网络模型"><a href="#1-1-神经网络模型" class="headerlink" title="1.1 神经网络模型"></a>1.1 神经网络模型</h3><p>&ensp;&ensp;&ensp; 所谓神经网络就是将许多个单一“神经元”联结在一起，这样，一个“神经元”的输出就可以是另一个“神经元”的输入。例如，下图就是一个简单的神经网络：<br><img src="https://github.com/HuanwenW/MyPostImag/blob/master/190408-NLP-gainian/shenjingwangluo-1.jpg?raw=true" alt="shenjingwangluo"><span class="img-alt">shenjingwangluo</span></p><h2 id="参考博客"><a href="#参考博客" class="headerlink" title="参考博客"></a>参考博客</h2><ol><li><a href="https://blog.csdn.net/SMith7412/article/details/88396674" target="_blank" rel="noopener">人工神经网络知识、激活函数、正则化、优化技术、Batch Normalization、Layer Normalization</a>  </li><li><a href="https://blog.csdn.net/qq_36047533/article/details/88419931" target="_blank" rel="noopener">神经网络基础</a>  </li><li><a href></a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;内容涵盖&quot;&gt;&lt;a href=&quot;#内容涵盖&quot; class=&quot;headerlink&quot; title=&quot;内容涵盖&quot;&gt;&lt;/a&gt;内容涵盖&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;前馈神经网络、网络层数、输入层、隐藏层、输出层、隐藏单元、激活函数的概念。&lt;/li&gt;
&lt;li&gt;感知机相关；利用t
      
    
    </summary>
    
    
      <category term="NLP" scheme="http://yoursite.com/categories/NLP/"/>
    
    
      <category term="Network" scheme="http://yoursite.com/tags/Network/"/>
    
  </entry>
  
  <entry>
    <title>Welcome to NLP-2019-huanhuan-homework-7</title>
    <link href="http://yoursite.com/2019/04/19/NLP/LDA/"/>
    <id>http://yoursite.com/2019/04/19/NLP/LDA/</id>
    <published>2019-04-19T08:52:33.000Z</published>
    <updated>2019-04-19T09:10:16.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="内容涵盖"><a href="#内容涵盖" class="headerlink" title="内容涵盖"></a>内容涵盖</h2><ul><li>pLSA、共轭先验分布；LDA主题模型原理</li><li>LDA应用场景 </li><li>LDA优缺点 </li><li>LDA 参数学习 </li><li>使用LDA生成主题特征，在之前特征的基础上加入主题特征进行文本分类  </li></ul><h2 id="LSA"><a href="#LSA" class="headerlink" title="LSA"></a>LSA</h2><p>&ensp;&ensp;&ensp;LSA(latent semantic analysis)潜在语义分析，也被称为 LSI(latent semantic index)，是 Scott Deerwester, Susan T. Dumais 等人在 1990 年提出来的一种新的索引和检索方法。该方法和传统向量空间模型(vector space model)一样使用向量来表示词(terms)和文档(documents)，并通过向量间的关系(如夹角)来判断词及文档间的关系；不同的是，LSA 将词和文档映射到潜在语义空间，从而去除了原始向量空间中的一些“噪音”，提高了信息检索的精确度。</p><h2 id="PLSA"><a href="#PLSA" class="headerlink" title="PLSA"></a>PLSA</h2><p>&ensp;&ensp;&ensp;概率隐语义分析（PLSA）是一个著名的针对文本建模的模型，是一个生成模型。因为加入了主题模型，所以可以很大程度上改善多词一义和一词多义的问题。Hoffmm在1999年提出了概率隐语义分析（Probabilistic Latent Semantic Analysis）。他认为每个主题下都有一个词汇的概率分布，而一篇文章通常由多个主题构成，并且文章中的每个单词都是由某个主题生成的。</p><h2 id="LDA"><a href="#LDA" class="headerlink" title="LDA"></a>LDA</h2><p>&ensp;&ensp;&ensp;LDA（Latent Dirichlet Allocation）是一种文档主题生成模型，也称为一个三层贝叶斯概率模型，包含词、主题和文档三层结构。所谓生成模型，就是说，我们认为一篇文章的每个词都是通过“以一定概率选择了某个主题，并从这个主题中以一定概率选择某个词语”这样一个过程得到。文档到主题服从多项式分布，主题到词服从多项式分布。</p><p>&ensp;&ensp;&ensp;LDA是一种非监督机器学习技术，可以用来识别大规模文档集（document collection）或语料库（corpus）中潜藏的主题信息。它采用了词袋（bag of words）的方法，这种方法将每一篇文档视为一个词频向量，从而将文本信息转化为了易于建模的数字信息。但是词袋方法没有考虑词与词之间的顺序，这简化了问题的复杂性，同时也为模型的改进提供了契机。每一篇文档代表了一些主题所构成的一个概率分布，而每一个主题又代表了很多单词所构成的一个概率分布。</p><p>&ensp;&ensp;&ensp; LSA（Latent semantic analysis，隐性语义分析）、pLSA（Probabilistic latent semantic analysis，概率隐性语义分析）和 LDA（Latent Dirichlet allocation，隐狄利克雷分配）这三种模型都可以归类到话题模型（Topic model，或称为主题模型）中。相对于比较简单的向量空间模型，主题模型通过引入主题这个概念，更进一步地对文本进行语义层面上的理解</p><h2 id="参考博客"><a href="#参考博客" class="headerlink" title="参考博客"></a>参考博客</h2><ol><li><a href="https://blog.csdn.net/yyy430/article/details/88346920" target="_blank" rel="noopener">朴素贝叶斯 &amp; SVM &amp; LDA文本分类</a>  </li><li><a href="https://blog.csdn.net/chen_yiwei/article/details/88370526" target="_blank" rel="noopener">LDA主题模型</a></li><li><a href="http://www.cnblogs.com/bentuwuying/p/6219970.html" target="_blank" rel="noopener">LSA，pLSA原理及其代码实现</a>  </li><li><a href="https://blog.csdn.net/qq_39422642/article/details/78730662" target="_blank" rel="noopener">主题模型（LDA）(一)–通俗理解与简单应用</a>  </li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;内容涵盖&quot;&gt;&lt;a href=&quot;#内容涵盖&quot; class=&quot;headerlink&quot; title=&quot;内容涵盖&quot;&gt;&lt;/a&gt;内容涵盖&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;pLSA、共轭先验分布；LDA主题模型原理&lt;/li&gt;
&lt;li&gt;LDA应用场景 &lt;/li&gt;
&lt;li&gt;LDA优缺点 
      
    
    </summary>
    
    
      <category term="NLP" scheme="http://yoursite.com/categories/NLP/"/>
    
    
      <category term="LDA" scheme="http://yoursite.com/tags/LDA/"/>
    
  </entry>
  
  <entry>
    <title>谱聚类（Spectral Clustering）算法概念及应用</title>
    <link href="http://yoursite.com/2019/04/16/MachineLearning/Pujulei/"/>
    <id>http://yoursite.com/2019/04/16/MachineLearning/Pujulei/</id>
    <published>2019-04-16T07:42:53.000Z</published>
    <updated>2019-04-17T07:30:04.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>&ensp;&ensp;&ensp;在研究图数据管理方面论文时候，《Label Informed Attributed Network Embedding》文章中提到对图结构表示用的是谱聚类方法，特来了解下该算法的原理。  </p><h2 id="参考博客"><a href="#参考博客" class="headerlink" title="参考博客"></a>参考博客</h2><p><a href="https://blog.csdn.net/gshgsh1228/article/details/52199870" target="_blank" rel="noopener">正则化1</a><br><a href="https://blog.csdn.net/haima1998/article/details/79425831" target="_blank" rel="noopener">正则化2</a><br><a href="https://blog.csdn.net/qq_14959801/article/details/81056025" target="_blank" rel="noopener">正则化3</a></p><p><a href="http://blog.pluskid.org/?page_id=683" target="_blank" rel="noopener">SVM</a>  </p><p>00.<a href="http://blog.pluskid.org/?p=287" target="_blank" rel="noopener">漫谈 Clustering (4): Spectral Clustering</a><br>00.<a href="https://blog.csdn.net/qq_30159015/article/details/83271065" target="_blank" rel="noopener">拉普拉斯矩阵（Laplacian matrix）</a><br>01.<a href="https://blog.csdn.net/Broccoli_Lian/article/details/79755225" target="_blank" rel="noopener">关联矩阵，邻接矩阵，拉普拉斯矩阵</a></p><p>0.<a href="https://blog.csdn.net/u012771351/article/details/53213993" target="_blank" rel="noopener">聚类系列-谱聚类</a><br>1.<a href="https://blog.csdn.net/qq_24519677/article/details/82291867" target="_blank" rel="noopener"><strong>谱聚类（Spectral Clustering）算法介绍</strong></a>  </p><ol start="2"><li><a href="https://www.cnblogs.com/pinard/p/6221564.html" target="_blank" rel="noopener"><strong>谱聚类（spectral clustering）原理总结</strong></a>  </li><li><a href="https://blog.csdn.net/u012500237/article/details/72864258" target="_blank" rel="noopener">聚类系列-谱聚类</a>  </li><li><a href="https://blog.csdn.net/zhangyi880405/article/details/39781817" target="_blank" rel="noopener">谱聚类算法详解</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;&amp;ensp;&amp;ensp;&amp;ensp;在研究图数据管理方面论文时候，《Label Informed Attributed Network Em
      
    
    </summary>
    
    
      <category term="技术篇" scheme="http://yoursite.com/categories/%E6%8A%80%E6%9C%AF%E7%AF%87/"/>
    
    
      <category term="聚类" scheme="http://yoursite.com/tags/%E8%81%9A%E7%B1%BB/"/>
    
  </entry>
  
  <entry>
    <title>Welcome to NLP-2019-huanhuan-homework-5</title>
    <link href="http://yoursite.com/2019/04/15/NLP/NLP-homework-5-Pushubeiyesi/"/>
    <id>http://yoursite.com/2019/04/15/NLP/NLP-homework-5-Pushubeiyesi/</id>
    <published>2019-04-15T11:00:35.000Z</published>
    <updated>2019-04-15T14:19:42.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="内容涵盖"><a href="#内容涵盖" class="headerlink" title="内容涵盖"></a>内容涵盖</h2><ul><li><strong>朴素贝叶斯的原理</strong>  </li><li><strong>朴素贝叶斯应用场景</strong>  </li><li><strong>朴素贝叶斯优缺点</strong>  </li><li><strong>朴素贝叶斯 sklearn 参数学习</strong>   </li><li><strong>利用朴素贝叶斯模型结合 Tf-idf 算法进行文本分类</strong>  </li></ul><h2 id="0-知识回顾"><a href="#0-知识回顾" class="headerlink" title="0.知识回顾"></a>0.知识回顾</h2><p><strong>(1) 联合概率</strong>  </p><p>&ensp;&ensp;&ensp;P(x)表示x发生的概率，P(y)表示y发生的概率，则 x，y 同时发生的概率为：  </p><p><img src="http://latex.codecogs.com/gif.latex?P(x,y)=P(x%7Cy)P(y)=P(y%7Cx)P(x)" alt></p><p>&ensp;&ensp;&ensp;特别的，当x，y独立时，上式可以写作：   </p><p><strong><img src="http://latex.codecogs.com/gif.latex?P(x,y)=P(x)P(y)" alt></strong>    </p><p>&ensp;&ensp;&ensp;原因在于，当x，y独立时，即x的发生与y的发生不相关，因此就有p(x|y)=p(x)，同理p(y|x)=p(y)。</p><p><strong>(2) 条件概率</strong> （是联合概率的变形，即把 条件事件 放在了等式左边）   </p><p><strong><img src="http://latex.codecogs.com/gif.latex?P(x%7Cy)=%5Cfrac%7BP(x,y)%7D%7BP(y)%7D" alt></strong>    </p><p> <strong><img src="http://latex.codecogs.com/gif.latex?P(y%7Cx)=%5Cfrac%7BP(x,y)%7D%7BP(x)%7D" alt></strong>    </p><p><strong>(3) 全概率</strong>   </p><p><strong><img src="http://latex.codecogs.com/gif.latex?P(x)=%5Csum_%7Bi=1%7D%5E%7BM%7DP(x%7Cy_%7Bi%7D)P(y_%7Bi%7D)" alt></strong>   </p><p>其中，<strong><img src="http://latex.codecogs.com/gif.latex?%5Csum_%7Bi=1%7D%5E%7BM%7DP(y_%7Bi%7D)" alt> = 1</strong> ，也就是说对于y的M种（所有）情况都要考虑到。</p><p><strong>(3) 贝叶斯</strong>   </p><p>贝叶斯理论指的是，根据一个已发生事件的概率，计算另一个事件的发生概率,<strong>贝叶斯公式：</strong>   </p><p><img src="http://latex.codecogs.com/gif.latex?P(y_%7Bi%7D%7Cx)=%5Cfrac%7BP(y_%7Bi%7D)P(y_%7Bi%7D%7Cx)%7D%7B%5Csum_%7Bj=1%7D%5E%7Bn%7DP(y_%7Bj%7D)P(x%7Cy_%7Bj%7D)%7D" alt></p><p>等同于我们经常简略表达：</p><p><strong><img src="http://latex.codecogs.com/gif.latex?P(Y%7CX)=%5Cfrac%7BP(X%7CY)P(Y)%7D%7BP(X)%7D" alt></strong></p><p>其中，<strong>X</strong>: 特征向量 &ensp;&ensp;&ensp; <strong>Y</strong>：类别<br>&ensp;&ensp;&ensp;&ensp; <strong>先验概率P(X)</strong>：是指根据以往经验和分析得到的概率。<br>&ensp;&ensp;&ensp;&ensp;<strong>后验概率P(Y|X)</strong> ：事情已经发生，要求这件事情发生的原因是由某个因素引起的可能性的大小。<br>&ensp;&ensp;&ensp;&ensp;<strong>类条件概率P(X|Y)</strong>：在已知某类别的特征空间中，出现特征值 <strong>X</strong> 的概率密度。 </p><h2 id="1-朴素贝叶斯原理"><a href="#1-朴素贝叶斯原理" class="headerlink" title="1.朴素贝叶斯原理"></a>1.朴素贝叶斯原理</h2><p>&ensp;&ensp;&ensp;贝叶斯分类是一类分类算法的总称，这类算法均以贝叶斯定理为基础，故统称为贝叶斯分类。而<strong>朴素贝叶斯分类是贝叶斯分类中最简单，也是常见的一种分类方法</strong>。</p><p><strong>朴素贝叶斯（naïve beyes）</strong> 法是基于 <strong>贝叶斯定理</strong> 与 <strong>特征条件独立假设</strong>的分类方法。—by李航《统计学习》</p><p>基于朴素贝叶斯公式，比较出后验概率的最大值来进行分类，后验概率的计算是由先验概率与类条件概率的乘积得出，先验概率和类条件概率要通过训练数据集得出，即为朴素贝叶斯分类模型，将其保存为中间结果，测试文档进行分类时调用这个中间结果得出后验概率。  </p><p>&ensp;&ensp;&ensp;</p><h2 id="2-朴素贝叶斯应用场景"><a href="#2-朴素贝叶斯应用场景" class="headerlink" title="2. 朴素贝叶斯应用场景"></a>2. 朴素贝叶斯应用场景</h2><h2 id="3-朴素贝叶斯优缺点"><a href="#3-朴素贝叶斯优缺点" class="headerlink" title="3.朴素贝叶斯优缺点"></a>3.朴素贝叶斯优缺点</h2><ul><li><strong>优点</strong>  </li></ul><p>(1) 算法逻辑简单,易于实现；<br>(2) 分类过程中时空开销小（假设特征相互独立，只会涉及到二维存储）</p><ul><li><strong>缺点</strong>  </li></ul><p>&ensp;&ensp;&ensp;理论上，朴素贝叶斯模型与其他分类方法相比具有最小的误差率。但是实际上并非总是如此，这是因为朴素贝叶斯模型<strong>假设属性之间相互独立</strong>，这个假设在实际应用中往往是不成立的，在属性个数比较多或者属性之间相关性较大时，分类效果不好。  </p><h2 id="4-朴素贝叶斯-sklearn-参数学习"><a href="#4-朴素贝叶斯-sklearn-参数学习" class="headerlink" title="4.朴素贝叶斯 sklearn 参数学习"></a>4.朴素贝叶斯 sklearn 参数学习</h2><h2 id="参考博客"><a href="#参考博客" class="headerlink" title="参考博客"></a>参考博客</h2><ol><li><a href="https://www.cnblogs.com/pinard/p/6069267.html" target="_blank" rel="noopener"><strong>朴素贝叶斯相关的统计学知识</strong></a></li><li><a href="https://blog.csdn.net/qq_35044025/article/details/79322169" target="_blank" rel="noopener"><strong>sklearn的机器学习之路：朴素贝叶斯</strong></a>  </li><li><a href="http://www.52nlp.cn/%E7%90%86%E8%AE%BA-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6%E4%B8%8E%E5%AE%9E%E4%BE%8B%E5%88%86%E6%9E%90#more-10451" target="_blank" rel="noopener"><strong>朴素贝叶斯模型算法研究与实例分析</strong></a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;内容涵盖&quot;&gt;&lt;a href=&quot;#内容涵盖&quot; class=&quot;headerlink&quot; title=&quot;内容涵盖&quot;&gt;&lt;/a&gt;内容涵盖&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;朴素贝叶斯的原理&lt;/strong&gt;  &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;朴素贝叶斯应用场景&lt;/
      
    
    </summary>
    
    
      <category term="NLP" scheme="http://yoursite.com/categories/NLP/"/>
    
    
      <category term="朴素贝叶斯" scheme="http://yoursite.com/tags/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/"/>
    
  </entry>
  
  <entry>
    <title>Welcome to NLP-2019-huanhuan-homework-4</title>
    <link href="http://yoursite.com/2019/04/13/NLP/NLP-homework-3/"/>
    <id>http://yoursite.com/2019/04/13/NLP/NLP-homework-3/</id>
    <published>2019-04-13T10:52:33.000Z</published>
    <updated>2019-09-13T04:33:59.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="内容涵盖"><a href="#内容涵盖" class="headerlink" title="内容涵盖"></a>内容涵盖</h2><ul><li><strong>TF-IDF原理</strong></li><li><strong>文本矩阵化，使用词袋模型，以TF-IDF特征值为权重</strong>（可以使用Python中TfidfTransformer库）</li><li><strong>互信息的原理</strong></li><li><strong>使用第二步生成的特征矩阵，利用互信息进行特征筛选</strong></li></ul><h2 id="1-TF-IDF原理"><a href="#1-TF-IDF原理" class="headerlink" title="1.TF-IDF原理"></a>1.TF-IDF原理</h2><p><strong>(1) 定义</strong><br>&ensp;&ensp;&ensp; TF-IDF(Term Frequency - Inverse Document Frequency)，即“词频-逆文本频率”。是一种用于资讯检索与资讯探勘的常用加权技术。TF-IDF是一种统计方法，用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。<strong>字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降.</strong>  </p><p><strong>(2)思想</strong><br>&ensp;&ensp;&ensp;如果某个词或短语在一篇文章中出现的频率TF高，并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分能力，适合用来分类。<strong>TF-IDF实际上就是 TF X IDF，其中TF表示词条在文章Document 中出现的频率；IDF其主要思想就是，如果包含某个词 Word的文档越少，则这个词的区分度就越大，也就是 IDF 越大。</strong> 对于如何获取一篇文章的关键词，我们可以计算这边文章出现的所有名词的 TF-IDF，TF-IDF越大，则说明这个名词对这篇文章的区分度就越高，取 TF-IDF 值较大的几个词，就可以当做这篇文章的关键词。</p><p><strong>(3) 计算步骤</strong><br><strong>a. 计算词频(TF)</strong>  </p><p><strong><img src="http://latex.codecogs.com/gif.latex?tf_%7Bi,j%7D=%5Cfrac%7Bn_%7Bi,j%7D%7D%7B%5Csum_%7B0%7D%5E%7Bk%7Dn_%7Bk,j%7D%7D" alt></strong>    </p><p>分子是该词在文件 dj 中的出现次数，而分母  则是在文件 dj 中所有字词的出现次数之和。</p><p><strong>b. 计算逆文档频率（IDF）</strong>   </p><h2 id="参考博客"><a href="#参考博客" class="headerlink" title="参考博客"></a>参考博客</h2><ol><li><a href="https://www.cnblogs.com/pinard/p/6693230.html" target="_blank" rel="noopener"><strong>文本挖掘预处理之TF-IDF</strong></a></li><li><a href="https://blog.csdn.net/lionel_fengj/article/details/53699903" target="_blank" rel="noopener"><strong>自然语言处理系列之TF-IDF算法</strong></a></li><li><a href="http://www.cnblogs.com/biyeymyhjob/archive/2012/07/17/2595249.html" target="_blank" rel="noopener"><strong>TF-IDF及其算法</strong></a></li><li><a href="https://www.jianshu.com/p/f3b92124cd2b" target="_blank" rel="noopener"><strong>使用不同的方法计算TF-IDF值</strong></a></li><li><a href="https://blog.csdn.net/u013710265/article/details/72848755" target="_blank" rel="noopener"><strong>sklearn-点互信息和互信息</strong></a></li><li><a href="https://baijiahao.baidu.com/s?id=1604074325918456186&wfr=spider&for=pc" target="_blank" rel="noopener"><strong>如何进行特征选择（理论篇）机器学习你会遇到的“坑”</strong></a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;内容涵盖&quot;&gt;&lt;a href=&quot;#内容涵盖&quot; class=&quot;headerlink&quot; title=&quot;内容涵盖&quot;&gt;&lt;/a&gt;内容涵盖&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;TF-IDF原理&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;文本矩阵化，使用词袋模型，
      
    
    </summary>
    
    
      <category term="NLP" scheme="http://yoursite.com/categories/NLP/"/>
    
    
      <category term="TF-IDF" scheme="http://yoursite.com/tags/TF-IDF/"/>
    
  </entry>
  
  <entry>
    <title>Welcome to NLP-2019-huanhuan-homework-6</title>
    <link href="http://yoursite.com/2019/04/13/NLP/NLP-homework-6/"/>
    <id>http://yoursite.com/2019/04/13/NLP/NLP-homework-6/</id>
    <published>2019-04-13T10:52:33.000Z</published>
    <updated>2019-04-17T12:11:36.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="内容涵盖"><a href="#内容涵盖" class="headerlink" title="内容涵盖"></a>内容涵盖</h1><ul><li>SVM的原理</li><li>SVM应用场景 </li><li>SVM优缺点 </li><li>SVM sklearn 参数学习 </li><li>利用SVM模型结合 Tf-idf 算法进行文本分类  </li></ul><h2 id="SVM的原理"><a href="#SVM的原理" class="headerlink" title="SVM的原理"></a>SVM的原理</h2><p>支持向量机（SVM）算法基于结构风险最小化原理，将数据集合压缩到支持向量集合，学习得到分类决策函数。这种技术解决了以往需要无穷大样本数量的问题，它只需要将一定数量的文本通过计算抽象成向量化的训练文本数据，提高了分类的精确率。支持向量机（SVM）算法是根据有限的样本信息，在模型的复杂性与学习能力之间寻求最佳折中，以求获得最好的推广能力支持向量机算法.  </p><h2 id="SVM优缺点"><a href="#SVM优缺点" class="headerlink" title="SVM优缺点"></a>SVM优缺点</h2><ol><li>专门针对有限样本情况，其目标是得到现有信息下的最优解而不仅仅是样本数量趋于无穷大时的最优值；  </li><li>算法最终转化为一个二次型寻优问题，理论上得到的是全局最优点，解决了在神经网络方法中无法避免的局部极值问题；  </li><li>支持向量机算法能同时适用于稠密特征矢量与稀疏特征矢量两种情况，而其他一些文本分类算法不能同时满足两种情况；  </li><li>支持向量机算法能够找出包含重要分类信息的支持向量，是强有力的增量学习和主动学习工具，在文本分类中具有很大的应用潜力。  </li></ol><h2 id="参考博客"><a href="#参考博客" class="headerlink" title="参考博客"></a>参考博客</h2><ol><li><a href="https://blog.csdn.net/yyy430/article/details/88346920" target="_blank" rel="noopener">朴素贝叶斯 &amp; SVM &amp; LDA文本分类</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;内容涵盖&quot;&gt;&lt;a href=&quot;#内容涵盖&quot; class=&quot;headerlink&quot; title=&quot;内容涵盖&quot;&gt;&lt;/a&gt;内容涵盖&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;SVM的原理&lt;/li&gt;
&lt;li&gt;SVM应用场景 &lt;/li&gt;
&lt;li&gt;SVM优缺点 &lt;/li&gt;
&lt;li&gt;SVM s
      
    
    </summary>
    
    
      <category term="NLP" scheme="http://yoursite.com/categories/NLP/"/>
    
    
      <category term="SVM" scheme="http://yoursite.com/tags/SVM/"/>
    
  </entry>
  
  <entry>
    <title>Welcome to NLP-2019-huanhuan-homework-3</title>
    <link href="http://yoursite.com/2019/04/11/MachineLearning/tezhentiqu/"/>
    <id>http://yoursite.com/2019/04/11/MachineLearning/tezhentiqu/</id>
    <published>2019-04-11T12:44:17.000Z</published>
    <updated>2019-04-12T08:02:42.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="内容涵盖"><a href="#内容涵盖" class="headerlink" title="内容涵盖"></a>内容涵盖</h2><ul><li>分词的正向最大、逆向最大、双向最大匹配法概念；</li><li>词、字符频率统计；（可以使用Python中的collections.Counter模块，也可以自己寻找其他好用的库）</li><li>语言模型中unigram、bigram、trigram的概念；</li><li>unigram、bigram频率统计；（可以使用Python中的collections.Counter模块，也可以自己寻找其他好用的库）</li><li>文本矩阵化：要求采用词袋模型且是词级别的矩阵化<br>步骤有：<br>3.1 分词（可采用结巴分词来进行分词操作，其他库也可以）；<br>3.2 去停用词；构造词表。<br>3.3 每篇文档的向量化。  </li></ul><h2 id="1-基本文本处理技能"><a href="#1-基本文本处理技能" class="headerlink" title="1. 基本文本处理技能"></a>1. 基本文本处理技能</h2><p>&ensp;&ensp;&ensp;Python中分分词工具很多，包括盘古分词、Yaha分词、Jieba分词、清华THULAC等。它们的基本用法都大同小异，本文以结巴分词 为例.  </p><p><strong>(1) 分词算法设计中的几个基本原则：</strong>  </p><p><strong>a.</strong>颗粒度越大越好：用于进行语义分析的文本分词，要求分词结果的颗粒度越大，即单词的字数越多，所能表示的含义越确切，如：“公安局长”可以分为“公安 局长”、“公安局 长”、“公安局长”都算对，但是要用于语义分析，则“公安局长”的分词结果最好（当然前提是所使用的词典中有这个词）</p><p><strong>b.</strong>切分结果中非词典词越少越好，单字字典词数越少越好，这里的“非词典词”就是不包含在词典中的单字，而“单字字典词”指的是可以独立运用的单字，如“的”、“了”、“和”、“你”、“我”、“他”。例如：“技术和服务”，可以分为“技术 和服 务”以及“技术 和 服务”，但“务”字无法独立成词（即词典中没有），但“和”字可以单独成词（词典中要包含），因此“技术 和服 务”有1个非词典词，而“技术 和 服务”有0个非词典词，因此选用后者。</p><p><strong>c.</strong>总体词数越少越好，在相同字数的情况下，总词数越少，说明语义单元越少，那么相对的单个语义单元的权重会越大，因此准确性会越高。</p><p><strong>(2) 匹配法：</strong><br>&ensp;&ensp;&ensp;最大匹配是指以词典为依据，取词典中最长单词为第一个次取字数量的扫描串，在词典中进行扫描（为提升扫描效率，还可以跟据字数多少设计多个字典，然后根据字数分别从不同字典中进行扫描）。例如：词典中最长词为“我爱北京天安门”共7个汉字，则最大匹配起始字数为7个汉字。然后逐字递减，在对应的词典中进行查找。<br><font color="#8A2BE2" size="3"><strong>&ensp;&ensp;下面以“我们在野生动物园玩”详细说明一下这几种匹配方法：</strong></font>       </p><p><strong>a. 正向最大匹配法</strong>  </p><p><strong>正向即从前往后取词，从7-&gt;1，每次减一个字，直到词典命中或剩下1个单字。</strong>   </p><p>第1次：“我们在野生动物”，扫描7字词典，无<br>第2次：“我们在野生动”，扫描6字词典，无<br><strong>……</strong><br>第6次：“我们”，扫描2字词典，有  </p><p><strong>扫描中止，输出第1个词为“我们”，去除第1个词后开始第2轮扫描，即：</strong>  </p><p>第1次：“在野生动物园玩”，扫描7字词典，无<br>第2次：“在野生动物园”，扫描6字词典，无<br><strong>……</strong><br>第6次：“在野”，扫描2字词典，有  </p><p><strong>扫描中止，输出第2个词为“在野”，去除第2个词后开始第3轮扫描，即：</strong>    </p><p>第1次：“生动物园玩”，扫描5字词典，无<br><strong>……</strong><br>第4次：“生动”，扫描2字词典，有</p><p><strong>扫描中止，输出第3个词为“生动”，第4轮扫描，即：</strong>    </p><p>第1次：“物园玩”，扫描3字词典，无<br>第2次：“物园”，扫描2字词典，无<br>第3次：“物”，扫描1字词典，无  </p><p><strong>扫描中止，输出第4个词为“物”，非字典词数加1，开始第5轮扫描，即：</strong>    </p><p>第1次：“园玩”，扫描2字词典，无<br>第2次：“园”，扫描1字词典，有  </p><p><strong>扫描中止，输出第5个词为“园”，单字字典词数加1，开始第6轮扫描，即：</strong>    </p><p>第1次：“玩”，扫描1字字典词，有</p><p><strong>扫描中止，输出第6个词为“玩”，单字字典词数加1，整体扫描结束。</strong>   </p><p><font color="#8A2BE2" size="3">*<em>正向最大匹配法，最终切分结果为：“我们/在野/生动/物/园/玩”，其中，单字字典词为2，非词典词为1。  *</em></font>   </p><p>*<em>b.逆向最大匹配法  *</em>  </p><p><strong>逆向即从后往前取词，其他逻辑和正向相同。即：</strong></p><p>第1轮扫描：“在野生动物园玩”<br>第1次：“在野生动物园玩”，扫描7字词典，无<br>第2次：“野生动物园玩”，扫描6字词典，无<br><strong>……</strong><br>第7次：“玩”，扫描1字词典，有  </p><p><strong>扫描中止，输出“玩”，单字字典词加1，开始第2轮扫描</strong>  </p><p>第2轮扫描：“们在野生动物园”<br>第1次：“们在野生动物园”，扫描7字词典，无<br>第2次：“在野生动物园”，扫描6字词典，无<br>第3次：“野生动物园”，扫描5字词典，有  </p><p><strong>扫描中止，输出“野生动物园”，开始第3轮扫描</strong></p><p>第3轮扫描：“我们在”<br>第1次：“我们在”，扫描3字词典，无<br>第2次：“们在”，扫描2字词典，无<br>第3次：“在”，扫描1字词典，有  </p><p><strong>扫描中止，输出“在”，单字字典词加1，开始第4轮扫描</strong></p><p>第4轮扫描：“我们”<br>第1次：“我们”，扫描2字词典，有  </p><p><strong>扫描中止，输出“我们”，整体扫描结束。</strong></p><p><font color="#8A2BE2" size="3"><strong>逆向最大匹配法，最终切分结果为：“我们/在/野生动物园/玩”，其中，单字字典词为2，非词典词为0。</strong></font>    </p><p><strong>c.双向最大匹配法</strong>     </p><p>&ensp;&ensp;&ensp;正向最大匹配法和逆向最大匹配法，都有其局限性，我举得例子是正向最大匹配法局限性的例子，逆向也同样存在（如：长春药店，逆向切分为“长/春药店”），因此有人又提出了双向最大匹配法，双向最大匹配法。即，两种算法都切一遍，然后根据大颗粒度词越多越好，非词典词和单字词越少越好的原则，选取其中一种分词结果输出。  </p><p>如：“我们在野生动物园玩”  </p><p>正向最大匹配法，最终切分结果为：“我们/在野/生动/物/园/玩”，其中，两字词3个，单字字典词为2，非词典词为1。  </p><p>逆向最大匹配法，最终切分结果为：“我们/在/野生动物园/玩”，其中，五字词1个，两字词1个，单字字典词为2，非词典词为0。  </p><p>非字典词：正向(1)&gt;逆向(0)（越少越好）  </p><p>单字字典词：正向(2)=逆向(2)（越少越好）  </p><p>总词数：正向(6)&gt;逆向(4)（越少越好）  </p><p>因此最终输出为逆向结果  </p><h2 id="参考博客"><a href="#参考博客" class="headerlink" title="参考博客"></a>参考博客</h2><ol><li><a href="https://github.com/fxsjy/jieba" target="_blank" rel="noopener">结巴中文分词理论+实践</a></li><li><a href="http://blog.sina.com.cn/s/blog_53daccf401011t74.html" target="_blank" rel="noopener">中文分词基础原则及正向最大匹配法、逆向最大匹配法、双向最大匹配法的分析</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;内容涵盖&quot;&gt;&lt;a href=&quot;#内容涵盖&quot; class=&quot;headerlink&quot; title=&quot;内容涵盖&quot;&gt;&lt;/a&gt;内容涵盖&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;分词的正向最大、逆向最大、双向最大匹配法概念；&lt;/li&gt;
&lt;li&gt;词、字符频率统计；（可以使用Python中的c
      
    
    </summary>
    
    
      <category term="NLP" scheme="http://yoursite.com/categories/NLP/"/>
    
    
  </entry>
  
</feed>
