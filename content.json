{"meta":{"title":"焕小妹","subtitle":"bug","description":"Bug多多  欢乐多多","author":"焕焕","url":"http://yoursite.com","root":"/"},"pages":[{"title":"","date":"2020-06-06T03:11:57.835Z","updated":"2019-09-15T09:23:10.544Z","comments":true,"path":"一些消息.html","permalink":"http://yoursite.com/一些消息.html","excerpt":"","text":"兼职代做各种算法设计： 淘宝店铺：【专业代做工科设计】https://m.tb.cn/h.ec9Xric?sm=71d228 点击链接，再选择浏览器咑閞；或復|制这段描述￥7DJfYYc8H7p￥后到淘寳 微信号：dida_daizuo"}],"posts":[{"title":"","slug":"MachineLearning/0-Convolution concept","date":"2020-06-06T01:59:42.932Z","updated":"2020-06-06T02:37:43.911Z","comments":true,"path":"2020/06/06/MachineLearning/0-Convolution concept/","link":"","permalink":"http://yoursite.com/2020/06/06/MachineLearning/0-Convolution concept/","excerpt":"","text":"对卷积的定义和意义的通俗解释教科书上一般定义函数的卷积如下： 连续形式： 离散形式： 公式解释，先对g函数进行翻转，相当于在数轴上把g函数从右边褶到左边去，也就是卷积的“卷”的由来。 然后再把g函数平移到n，在这个位置对两个函数的对应点相乘，然后相加，这个过程是卷积的“积”的过程。 这个只是从计算的方式上对公式进行了解释，从数学上讲无可挑剔，但进一步追问，为什么要先翻转再平移，这么设计有何用意？还是有点费解的。 好在有万能的互联网，尤其是知乎，CSDN这样的网站，很多的热心网友对卷积举了很多形象的例子进行了解释，如卷地毯、丢骰子、打耳光、存钱等等，参见知乎上这两个两个经典的问题，回答的人很多： 如何通俗易懂地解释卷积？https://www.zhihu.com/question/22298352 卷积为什么叫「卷」积？ https://www.zhihu.com/question/54677157 读完觉得非常生动有趣，但过细想想，还是感觉有些地方还是没解释清楚，甚至可能还有瑕疵，或者还可以改进（这些后面我会做一些分析）。 ==明确一下，这篇文章主要想解释两个问题：== 卷积这个名词是怎么解释？“卷”是什么意思？“积”又是什么意思？ 卷积背后的意义是什么，该如何解释？ 对卷积的理解对卷积这个名词的理解：所谓两个函数的卷积，本质上就是先将一个函数翻转，然后进行滑动叠加。 在连续情况下，叠加指的是对两个函数的乘积求积分，在离散情况下就是加权求和，为简单起见就统一称为叠加。 整体看来是这么个过程： ​ 翻转——&gt;滑动——&gt;叠加——&gt;滑动——&gt;叠加——&gt;滑动——&gt;叠加….. 多次滑动得到的一系列叠加值，构成了卷积函数。 卷积的“卷”，指的的函数的翻转，从 g(t) 变成 g(-t) 的这个过程； 卷积的“积”，指的是滑动积分/加权求和。 有些文章只强调滑动叠加求和，而没有说函数的翻转，我觉得是不全面的；有的文章对“卷”的理解其实是“积”，我觉得是张冠李戴。 ==对卷积的意义的理解：== 从“积”的过程可以看到，我们得到的叠加值，是个全局的概念。以信号分析为例，卷积的结果是不仅跟当前时刻输入信号的响应值有关，也跟过去所有时刻输入信号的响应都有关系，考虑了对过去的所有输入的效果的累积。在图像处理的中，卷积处理的结果，其实就是把每个像素周边的，甚至是整个图像的像素都考虑进来，对当前像素进行某种加权处理。所以说，“积”是全局概念，或者说是一种“混合”，把两个函数在时间或者空间上进行混合。 那为什么要进行“卷”？直接相乘不好吗？我的理解，进行“卷”（翻转）的目的其实是施加一种约束，它指定了在“积”的时候以什么为参照。在信号分析的场景，它指定了在哪个特定时间点的前后进行“积”，在空间分析的场景，它指定了在哪个位置的周边进行累积处理。 考虑的应用场景为了更好地理解这些问题，我们先给出两个典型的应用场景： 信号分析 一个输入信号f(t)，经过一个线性系统（其特征可以用单位冲击响应函数g(t)描述）以后，输出信号应该是什么？实际上通过卷积运算就可以得到输出信号。 图像处理 输入一幅图像f(x,y)，经过特定设计的卷积核g(x,y)进行卷积处理以后，输出图像将会得到模糊，边缘强化等各种效果。 举例说明下面举几个例子说明为什么要翻转，以及叠加求和的意义。 例1：信号分析如下图所示，输入信号是 f(t) ，是随时间变化的。系统响应函数是 g(t) ，图中的响应函数是随时间指数下降的，它的物理意义是说：如果在 t=0 的时刻有一个输入，那么随着时间的流逝，这个输入将不断衰减。换言之，到了 t=T时刻，原来在 t=0 时刻的输入f(0)的值将衰减为f(0)g(T)。 考虑到信号是连续输入的，也就是说，每个时刻都有新的信号进来，所以，最终输出的是所有之前输入信号的累积效果。如下图所示，在T=10时刻，输出结果跟图中带标记的区域整体有关。其中，f(10)因为是刚输入的，所以其输出结果应该是f(10)g(0)，而时刻t=9的输入f(9)，只经过了1个时间单位的衰减，所以产生的输出应该是 f(9)g(1)，如此类推，即图中虚线所描述的关系。这些对应点相乘然后累加，就是T=10时刻的输出信号值，这个结果也是f和g两个函数在T=10时刻的卷积值。 显然，上面的对应关系看上去比较难看，是拧着的，所以，我们把g函数对折一下，变成了g(-t)，这样就好看一些了。看到了吗？这就是为什么卷积要“卷”，要翻转的原因，这是从它的物理意义中给出的。 上图虽然没有拧着，已经顺过来了，但看上去还有点错位，所以再进一步平移T个单位，就是下图。它就是本文开始给出的卷积定义的一种图形的表述： 所以，在以上计算T时刻的卷积时，要维持的约束就是： ==t+ (T-t) = T== 。这种约束的意义，大家可以自己体会。 例2：丢骰子在知乎问题 如何通俗易懂地解释卷积？中排名第一的 马同学在中举了一个很好的例子（下面的一些图摘自马同学的文章，在此表示感谢），用丢骰子说明了卷积的应用。 要解决的问题是：有两枚骰子，把它们都抛出去，两枚骰子点数加起来为4的概率是多少? 分析一下，两枚骰子点数加起来为4的情况有三种情况：1+3=4， 2+2=4, 3+1=4 因此，两枚骰子点数加起来为4的概率为： 写成卷积的方式就是： 在这里我想进一步用上面的翻转滑动叠加的逻辑进行解释。 首先，因为两个骰子的点数和是4，为了满足这个约束条件，我们还是把函数 g 翻转一下，然后阴影区域上下对应的数相乘，然后累加，相当于求自变量为4的卷积值，如下图所示： 进一步，如此翻转以后，可以方便地进行推广去求两个骰子点数和为 n 时的概率，为f 和 g的卷积 f\\g(n)*，如下图所示： 由上图可以看到，函数 g 的滑动，带来的是点数和的增大。这个例子中对f和g的约束条件就是点数和，它也是卷积函数的自变量。有兴趣还可以算算，如果骰子的每个点数出现的概率是均等的，那么两个骰子的点数和n=7的时候，概率最大。 例3：图像处理还是引用知乎问题 如何通俗易懂地解释卷积？中 马同学的例子。图像可以表示为矩阵形式（下图摘自马同学的文章）： 对图像的处理函数（如平滑，或者边缘提取），也可以用一个g矩阵来表示，如： 注意，我们在处理平面空间的问题，已经是二维函数了，相当于： 那么函数f和g的在（u，v）处的卷积 该如何计算呢？ 首先我们在原始图像矩阵中取出（u,v）处的矩阵：【u代表纵向，v代表横向，矩阵坐标是表示相对位置，而==不是==坐标系中的象限坐标(上加下减，左减右加)-hh】 然后将图像处理矩阵翻转（延x轴和y轴两个方向翻转），如下： 计算卷积时，就可以用和的内积： 请注意，以上公式有一个特点，做乘法的两个对应变量a,b的下标之和都是（u,v），其目的是对这种加权求和进行一种约束。这也是为什么要将矩阵g进行翻转的原因。 以上计算的是（u,v）处的卷积，延x轴或者y轴滑动，就可以求出图像中各个位置的卷积，其输出结果是处理以后的图像（即经过平滑、边缘提取等各种处理的图像）。 再深入思考一下，在算图像卷积的时候，我们是直接在原始图像矩阵中取了（u,v）处的矩阵，为什么要取这个位置的矩阵，本质上其实是为了满足以上的约束。因为我们要算（u，v）处的卷积，而g矩阵是3x3的矩阵，要满足下标跟这个3x3矩阵的和是（u,v），只能是取原始图像中以（u，v）为中心的这个3x3矩阵，即图中的阴影区域的矩阵。 ==【下面仅是摘录，并未理解-hh】== 推而广之，如果如果g矩阵不是3x3，而是6x6，那我们就要在原始图像中取以（u，v）为中心的6x6矩阵进行计算。由此可见，这种卷积就是把原始图像中的相邻像素都考虑进来，进行混合。相邻的区域范围取决于g矩阵的维度，维度越大，涉及的周边像素越多。而矩阵的设计，则决定了这种混合输出的图像跟原始图像比，究竟是模糊了，还是更锐利了。 比如说，如下图像处理矩阵将使得图像变得更为平滑，显得更模糊，因为它联合周边像素进行了平均处理： 而如下图像处理矩阵将使得像素值变化明显的地方更为明显，强化边缘，而变化平缓的地方没有影响，达到提取边缘的目的： 附录对卷积的定义和意义的通俗解释-物理角度从一维升级为二维","categories":[],"tags":[]},{"title":"","slug":"English/paper格式","date":"2019-11-11T02:27:16.226Z","updated":"2019-11-11T03:29:46.935Z","comments":true,"path":"2019/11/11/English/paper格式/","link":"","permalink":"http://yoursite.com/2019/11/11/English/paper格式/","excerpt":"","text":"空行 ​ \\ \\hspace*{\\fill} \\ 罗列点 \\begin{enumerate}[labelsep = .5em, leftmargin = 0pt, itemindent = 3em] \\item[·]RQ1: How does XXXX perform as compared with state-of-the-art methods? \\item[·]RQ1: How do different hyper-parameter settings (e.g., depth of layer, embedding propagation layer, layer-aggregation mechanism,different connecting of network) affect XXXX? \\item[·]How much impact does the splitting of the data have on the experiment? \\end{enumerate} 插入表格2种方式 顶端插入 \\begin{table} \\centering \\caption{Statistics of the datasets.} \\begin{tabular}{cccccc} \\toprule Dataset &amp; items &amp; clicks &amp; train &amp; test &amp; avglen \\ \\toprule Steve Jobs&amp; 001&amp; Male&amp; Male&amp; Male&amp; Male\\ \\midrule %添加表格中横线 Bill Gates&amp; 002&amp; Female&amp; Male&amp; Male&amp; Male\\ \\midrule %添加表格中横线 Bill Gates&amp; 002&amp; Female&amp; Male&amp; Male&amp; Male\\ \\bottomrule \\end{tabular} \\label{tbl:table-example} \\end{table} 中间插入 \\begin{tabular}{cccccc} % c控制列数 \\toprule %添加表格头部粗线 Dataset &amp; items &amp; clicks &amp; train &amp; test &amp; avglen \\ \\midrule %添加表格中横线 Steve Jobs&amp; 001&amp; Male&amp; Male&amp; Male&amp; Male\\ \\midrule %添加表格中横线 Bill Gates&amp; 002&amp; Female&amp; Male&amp; Male&amp; Male\\ \\midrule %添加表格中横线 Bill Gates&amp; 002&amp; Female&amp; Male&amp; Male&amp; Male\\ \\bottomrule %添加表格底部粗线 \\end{tabular}","categories":[],"tags":[]},{"title":"","slug":"English/EglishPaper","date":"2019-11-02T09:08:36.884Z","updated":"2019-11-02T09:11:25.935Z","comments":true,"path":"2019/11/02/English/EglishPaper/","link":"","permalink":"http://yoursite.com/2019/11/02/English/EglishPaper/","excerpt":"","text":"英文字母缩写 e.g. 的全称是 exampli gratia，意为“例如”。 可以代替”for example; for instance;such as”等。如: Buy some vegetables, e.g., carrots. 注：1、e 和 g 后面都有“.” 经常出现的错误是，忘记 e 后面的“.” 2、最好把 e.g. 连同它的例子放在括号中，如 I like quiet activities (e.g., reading)","categories":[],"tags":[]},{"title":"np.where","slug":"pythonLearning/np.where()","date":"2019-10-14T07:48:25.000Z","updated":"2019-10-14T11:34:33.292Z","comments":true,"path":"2019/10/14/pythonLearning/np.where()/","link":"","permalink":"http://yoursite.com/2019/10/14/pythonLearning/np.where()/","excerpt":"","text":"一、np.where()用法 np.where(condition,x,y) 当where内有三个参数时，第一个参数表示条件，当条件成立时where方法返回x，当条件不成立时where返回y np.where(condition) 当where内只有一个参数时，那个参数表示条件，当条件成立时，where返回的是每个符合condition条件元素的坐标,返回的是以元组的形式 代码示例1234567891011# 用法2示例&gt;&gt;&gt; import numpy as np&gt;&gt;&gt; a = np.array([2,4,6,8,10]) # 初始化一个数组a&gt;&gt;&gt; np.where(a&gt;5) # 筛选出a数组中大于5的元素(array([2, 3, 4]),) # 得到的是 元组形式 的元素对应的 下标 位置&gt;&gt;&gt; np.where(a&gt;5)[0] array([2, 3, 4])&gt;&gt;&gt; np.where(a&gt;5)[0][0] # 取第0个下标2&gt;&gt;&gt; np.where(a&gt;5)[0][1] # 取第1个下标3 参考np.where()的用法","categories":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"List---python for循环生成列表","slug":"pythonLearning/Python for循环生成列表","date":"2019-10-14T07:48:25.000Z","updated":"2019-10-14T11:15:29.716Z","comments":true,"path":"2019/10/14/pythonLearning/Python for循环生成列表/","link":"","permalink":"http://yoursite.com/2019/10/14/pythonLearning/Python for循环生成列表/","excerpt":"","text":"吓人的语句12featList = [example[i] for example in dataSet]classList = [example[-1] for example in dataSet] 一般Python for语句前不加语句，但我在机器学习实战中看到了上面这种语句 解释语句featList = [example[i] for example in dataSet]作用为： 将 dataSet 中的数据按行依次放入example中，然后取得example中的example[ i ]元素，放入列表featList中 语句classList = [example[-1] for example in dataSet]作用为： 将dataSet中的数据按行依次放入example中，然后取得example中的example[-1]元素，放入列表classList中 总而言之，类似上述两种for循环形式可以很方便地用来创建列表， 举例12345list_0 = [x*x for x in range(5)] # range(5)= 0，1，2，3，4print(list_0)#输出：#[0, 1, 4, 9, 16] 参考资料python for 循环列表","categories":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"Xcode 的安装使用","slug":"software-install/Xcode","date":"2019-10-06T01:55:27.000Z","updated":"2019-10-06T02:59:24.703Z","comments":true,"path":"2019/10/06/software-install/Xcode/","link":"","permalink":"http://yoursite.com/2019/10/06/software-install/Xcode/","excerpt":"","text":"背景为了做一名合格的助教，决定自己写代码验证（其实也是为了完成老师要求每周出2道题目的需求），可是mac电脑上没有C++环境，于是乎各种知乎，寻找mac上比较好的编译工具，Xcode呼声很高，于是乎各种倒腾起来 正文 下载code2种途径 App Store 商店直接下载 官网下载 按照步骤安装即可 使用方法及遇到的问题见参考链接 参考链接创建c++项目 写程序示例 调试功能","categories":[{"name":"技术篇","slug":"技术篇","permalink":"http://yoursite.com/categories/技术篇/"}],"tags":[{"name":"软件安装","slug":"软件安装","permalink":"http://yoursite.com/tags/软件安装/"}]},{"title":"Mac 上安装及使用 VScode 和 TeX","slug":"software-install/Mac 上安装及使用 VScode 和 TeX","date":"2019-10-06T01:55:27.000Z","updated":"2019-10-06T03:01:29.201Z","comments":true,"path":"2019/10/06/software-install/Mac 上安装及使用 VScode 和 TeX/","link":"","permalink":"http://yoursite.com/2019/10/06/software-install/Mac 上安装及使用 VScode 和 TeX/","excerpt":"","text":"背景据说学术论文在latex上写后期改起来非常方便，于是乎开一波在mac上安装latex编辑器浪潮。本着勤俭节约（不付费）的精神，在希望与绝望中各种跳坑！ 参考链接 Mac 上使用 TeX","categories":[{"name":"技术篇","slug":"技术篇","permalink":"http://yoursite.com/categories/技术篇/"}],"tags":[{"name":"软件安装","slug":"软件安装","permalink":"http://yoursite.com/tags/软件安装/"}]},{"title":"","slug":"English/English","date":"2019-09-21T12:33:44.192Z","updated":"2019-09-21T13:40:49.234Z","comments":true,"path":"2019/09/21/English/English/","link":"","permalink":"http://yoursite.com/2019/09/21/English/English/","excerpt":"","text":"汇总 主格 宾格 形容词性物主代词 名词性物主代词 反生代词 I me my mine myself you you your yours yourself he him his his himself she her her hers herself It it its its itself We us our ours ourselves you you your yours yourselves they them their theirs themselves","categories":[],"tags":[]},{"title":"Ubantu下修改文件权限命令","slug":"software-install/ubantu xiugaiquanxian","date":"2019-09-21T03:57:15.000Z","updated":"2019-09-21T04:30:07.290Z","comments":true,"path":"2019/09/21/software-install/ubantu xiugaiquanxian/","link":"","permalink":"http://yoursite.com/2019/09/21/software-install/ubantu xiugaiquanxian/","excerpt":"","text":"问题背景安装某软件时报错，搜索解决方案说要把XX文件夹删除，带着忐忑，先备份到另一个文件夹，然后命令删除XX文件夹，然后此方案并没有解决之前问题，于是乎各种搜索还原已被删除的XX文件夹 整体思路方案一：用命令直接将备份的 XX文件夹 移动到原有位置，由于权限问题以失败告终 方案二：很笨，最后成功了 原有目录下创建 XX文件夹 1sudo mkdir XX文件夹名称 切换到 XX文件夹下，依次创建原有的 xxx文件 12cd /XX文件夹名称sudo touch xxx文件 依次将 备份的XX文件夹中的 xxx文件中的内容复制粘贴，此过程遇到问题如下： 发现所创建的文件为 只读，无法 粘贴 修改文件权限 1sudo chmod 666 ×××文件 此时 xxx文件具有写的权限，依次重复所有文件即可。 为了防止其他问题出现，我将所有我修改过权限的文件，在写入内容后，又恢复了只读 1sudo chmod 644 ×××文件 依次修改所有写好内容的文件即可 修改文件权限常用方法如下：sudo chmod 600 ××× （只有所有者有读和写的权限）sudo chmod 644 ××× （所有者有读和写的权限，组用户只有读的权限）sudo chmod 700 ××× （只有所有者有读和写以及执行的权限）sudo chmod 666 ××× （每个人都有读和写的权限）sudo chmod 777 ××× （每个人都有读和写以及执行的权限） 其中×××指文件名（也可以是文件夹名，不过要在chmod后加-ld）。 解释一下，其实整个命令的形式是sudo chmod -（代表类型）×××（所有者）×××（组用户）×××（其他用户） 三位数的每一位都表示一个用户类型的权限设置。取值是0～7，即二进制的[000]~[111]。 这个三位的二进制数的每一位分别表示读、写、执行权限。 如000表示三项权限均无，而100表示只读。这样，我们就有了下面的对应：0 [000] 无任何权限4 [100] 只读权限6 [110] 读写权限7 [111] 读写执行权限 现在看上面的几个常用用法就非常清楚了。试着自己来修改权限吧 参考 ubuntu下修改文件夹权限","categories":[{"name":"software","slug":"software","permalink":"http://yoursite.com/categories/software/"}],"tags":[{"name":"Version","slug":"Version","permalink":"http://yoursite.com/tags/Version/"}]},{"title":"Ubantu下常用的文件操作命令","slug":"software-install/ubantu-based","date":"2019-09-21T03:57:15.000Z","updated":"2019-09-21T04:27:36.841Z","comments":true,"path":"2019/09/21/software-install/ubantu-based/","link":"","permalink":"http://yoursite.com/2019/09/21/software-install/ubantu-based/","excerpt":"","text":"ubantu下的常用命令相关命令 cd 路径 （进入一个路径，比如cd /usr/local/lib） cd .. （返回上一个文件夹） ls （显示当前文件夹下的所有文件，Linux独有哦，dir 也有相同功能） sudo 命令 （获取超级管理权限，需要输入密码） 常用新建、删除、拷贝命令 mkdir 目录名 （新建一个文件夹，文件夹在Linux系统中叫做“目录”） touch 文件名 （新建一个空文件） rmdir 目录名 （删除一个空文件夹，文件夹里有内容则不可用） rm -rf 非空目录名 （删除一个包含文件的文件夹） rm 文件名 文件名 （删除多个文件） cp 文件名 目标路径（拷贝一个文件到目标路径，如cp hserver /opt/hqueue） cp -i （拷贝，同名文件存在时，输出 [yes/no] 询问是否执行） cp -f （强制复制文件，如有同名不询问） 例如：将/home/wally/test中 test.c 的文件复制到/local/arm 中，命令为： cd /wally/test ls sudo cp -i test.c /local/arm 常用解压、安装程序、文件更新命令：deb格式双击即可安装 tar -zxvf *.tar.gz ( 解压 tar.gz格式的文件 ) source *.install （安装install格式的安装包） sh 路径/×.sh （安装sh格式的文件，如 sudo sh /home/hp/Downloads/*.sh） sudo apt-get upgrade（更新已安装的包） sudo apt-get update （更新源） 参考 Ubuntu系统下常用的新建、删除、拷贝文件命令","categories":[{"name":"software","slug":"software","permalink":"http://yoursite.com/categories/software/"}],"tags":[{"name":"Version","slug":"Version","permalink":"http://yoursite.com/tags/Version/"}]},{"title":"重零开始安装Ubantu18.04+nvidia-410显卡驱+cuda10.0","slug":"software-install/ubantuSystem","date":"2019-09-20T12:55:27.000Z","updated":"2019-09-20T08:58:57.396Z","comments":true,"path":"2019/09/20/software-install/ubantuSystem/","link":"","permalink":"http://yoursite.com/2019/09/20/software-install/ubantuSystem/","excerpt":"","text":"背景为了paper实验，各种周折后，2019.09入手一台新电脑，显卡配置为华硕RTX2080Ti，于是乎小白开始为电脑安装ubantu18.0及系统内nvidia-410显卡驱、CUDA10.0、cuDNN v7.3.1、ananconda3、ananconda2、tensorflow之旅奔波 友情提醒安装过程中所下载好的软件包，备份到移动硬盘，防止系统重装，避免浪费不必要的软件下载时间 相关工作在终端查看CUDNN版本：（附件1） 1cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2 安装输入法报错，解决方案参考4 输入法靠谱详细教程讲解 解决Ubuntu 18.04中文输入法的问题，安装搜狗拼音 不用外网就能安装的google chrome教程 Ubuntu 安装 Google Chrome 浏览器 参考 Ubuntu18.04+RTX2080+cuda10+tensorflow Ubuntu18.04安装Cuda10.1/Cudnn Ubuntu 18.04 安装 PyCharm E:Sub-process /usr/bin/dpkg returned an error code (1)错误解决 Ubantu 无法识别 （希捷）移动硬盘本人的为ubuntu18.04 (64位)，ubuntu14、ubuntu14解决办法应该一样，其他的未测试。 解决方式如下，运行命令: sudo apt-get install exfat-fuse exfat-utils 参考Ubuntu无法挂载移动硬盘","categories":[{"name":"装机篇","slug":"装机篇","permalink":"http://yoursite.com/categories/装机篇/"}],"tags":[{"name":"software installs","slug":"software-installs","permalink":"http://yoursite.com/tags/software-installs/"}]},{"title":"uUbantu18.04安装nvidia-410显卡驱（华硕2080Ti）","slug":"software-install/ubantu18.04 install drive","date":"2019-09-19T13:55:27.000Z","updated":"2019-09-20T01:02:34.973Z","comments":true,"path":"2019/09/19/software-install/ubantu18.04 install drive/","link":"","permalink":"http://yoursite.com/2019/09/19/software-install/ubantu18.04 install drive/","excerpt":"","text":"本驱动安装流程简介卸载ubantu自带驱动——添加PPA源——安装对应版本的驱动 具体步骤： 为了保证不必要的冲突，先卸载原有驱动 1sudo apt-get remove --purge nvidia* #卸载原有驱动 禁用nouveau驱动，非必要步骤，可跳过 1sudo gedit /etc/modprobe.d/blacklist.conf #打开文本 在打开的文本最后添加以下内容： 12blacklist nouveauoptions nouveau modeset=0 保存退出后执行： 1sudo update-initramfs -u （重启后，执行：lsmod | grep nouveau。如果没有屏幕输出，说明禁用nouveau成功。） 添加PPA源 12sudo add-apt-repository ppa:graphics-drivers/ppasudo apt-get update 安装驱动 1sudo apt-get install nvidia-driver-410 注：软件包的名字需要写正确，比如如果写成下面的会报则会报错 E：无法定位软件包 nvidia-410 1sudo apt-get install nvidia-410 安装成功，重启电脑，输入下面命令确认是否安装成 1nvidia-smi 若显示下图则表示安装成功： 各参数含义 表格第一行：分别表示 nvidia显卡对应的版本：410.104，CUDA版本：10.0 注意：电脑后期装cuda需同显卡版本对应，即cuda版本为10.0,安装cuda10请跳转本链接 表格第二行依次为风扇等 表格下面的processes表示现在电脑的进程使用情况 参考链接 ubuntu18.04 安装nvidia显卡驱动","categories":[{"name":"装机篇","slug":"装机篇","permalink":"http://yoursite.com/categories/装机篇/"}],"tags":[{"name":"software installs","slug":"software-installs","permalink":"http://yoursite.com/tags/software-installs/"}]},{"title":"Hexo+github 从windows到mac的迁移（小白水平）","slug":"software-install/Hexo+github 从windows到mac的迁移（超详细步骤及遇到问题解决）","date":"2019-09-14T13:55:27.000Z","updated":"2020-06-06T04:02:02.349Z","comments":true,"path":"2019/09/14/software-install/Hexo+github 从windows到mac的迁移（超详细步骤及遇到问题解决）/","link":"","permalink":"http://yoursite.com/2019/09/14/software-install/Hexo+github 从windows到mac的迁移（超详细步骤及遇到问题解决）/","excerpt":"","text":"背景2019的年5月在惠普笔记本搭建了个hexo+github版人博客就；2019的6月刚入手了一个mac，于是乎各种东西都得由windows转移到mac;hexo的搬家路：windows - &gt; MacBook Pro 总体思路自己也算是摸爬滚打搭建迁移成功，把完整步骤分享给大家，同时最后有一些参考链接，如果我的步骤有问题，大家可以参考其他人的. 理清思路真不难，过程要细心、耐心，大概分为以下三个模块： 首先在mac电脑上安装好hexo，并初始化根目录; 然后生成新的SSH key，并将其添加到github上; 将旧电脑中的三个文件，直接粘贴覆盖在新电脑对应的目录。 言归正传一. 安装hexo前奏1. 安装Homebrew（下载速度有点慢，耐心~~）Homebrew安装过程很简单，直接打开mac电脑的Terminal命令窗口，把下面的代码粘贴一下，按回车键执行即可，安装过程中两次停顿，分别需要输入 y 和 电脑密码 /usr/bin/ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\" 查看安装是否成功命令： brew --version 安装成功提示版本号，如下图 2. 安装git先检查下电脑是否已存在Git，若mac自带git，此步可以跳过，查看命令如下 git --version 若不存在，使用brew安装Git，安装命令如下 brew install git 同样，输入**git --version** 验证是否安装成功 安装成功提示版本号，如下图 3. 安装node输入命令如下 brew install node 检查安装是否成功，一定要安装成功，否者否许操作中会报错 node --version 安装成功提示版本号，如下图 二. Hexo的安装及初始化1. 用 node 的 npm 安装 hexo，命令如下（下载速度有点慢，耐心~~） sudo npm install --unsafe-perm=true -g hexo-cli ### 2. 初始化hexo 创建HexoBlog（名字根据个人喜好自取）文件夹,输入下面命令： hexo init HexoBlog ！！！报错提示及解决方案 3. 体验hexo魅力​ 由于初始化hexo 之后source目录下自带一篇hello world文章, 所以依次执行下方两个命令：&ensp;注意：执行下面命令前要先进入blog文件夹中重新打开git命令窗口！！！ $ hexo generate 命令含义： 生成静态文件，等价于(可简写为)： `hexo g` $ hexo server 命令含义： 启动本地服务器，等价于(可简写为)： `hexo s` 打开浏览器，输入网址： http://localhost:4000/ ，即可看到网站初步的模样。 三. mac生成SSH及配置1. 先检查一下本机的 SSH key是否已存在 ls -a ~/.ssh 如果输出以下内容（xxx和xxx.pub成对存在）说明ssh key存在(输入这个命令也行：ls ~/.ssh) 2. 若不存在，输入以下命令，生成ssh Key ssh -T git@github.com //git@github.com为邮箱地址？ 3. 你可能找不命令窗口提示所生成的ssh在哪里，此时可直接用命令打开.ssh文件 open ~/.ssh ### 4. 复制id_rsa.pub里面的所有内容 手动打开id_rsa.pub文件，复制里面的所有内容 直接在终端打开文件，复制生成内容，打开文件命令如下 cat ~/.ssh/id_rsa.pub ### 5. 进入github配置ssh 然后进入进入自己的github页面，找到setting下的SSH：链接 依次执行下面步骤：点击 New SSH key —— Title：blog —— Key：输入刚才复制的内容 —— Add SSH key d. 测试一下是否成功,输入下方命令： $ ssh -T git@github.com //Github的注册邮箱地址 ![](https://github.com/HuanwenW/MyPostImag/blob/master/190410-boke/github-3.png?raw=true) &ensp;&ensp;&ensp;看到上面信息说明SSH已配置成功！ 四. 替换_config.yml 、thems、source 文件从windows电脑中复制_config.yml 、thems、source三个文件 ，替换mac下的_config.yml 、thems、source 三个文件，即可完成原主题的迁移 五. 主题相关设置专题此处不在啰嗦，完全参照hexo搭建模版参照教程的讲解 也可以参考我的window版本搭建hexo中第四部分如何将github和hexo联系起来？的详细说明 参考链接 hexo从windows转移至Mac MAC搭建个人博客hexo+github详细完整步骤 Mac系统下安装和卸载HomeBrew的方法 Mac安装，简单使用，卸载homebrew详细教程 解决hexo -d 报错问题 npm权限问题 mac下 ssh key 的获取 hexo搭建模版参照教程 用flowchart.js画流程图","categories":[{"name":"技术篇","slug":"技术篇","permalink":"http://yoursite.com/categories/技术篇/"}],"tags":[{"name":"软件安装","slug":"软件安装","permalink":"http://yoursite.com/tags/软件安装/"}]},{"title":"ubantu系统中的anaconda3下安装anaconda2","slug":"software-install/Annaconda3withAnaconda2","date":"2019-09-14T13:55:27.000Z","updated":"2019-09-20T03:23:55.150Z","comments":true,"path":"2019/09/14/software-install/Annaconda3withAnaconda2/","link":"","permalink":"http://yoursite.com/2019/09/14/software-install/Annaconda3withAnaconda2/","excerpt":"","text":"背景ubantu系统已经安装有anaconda3，但是要跑的实验使用的是python2.7，需要更换为anaconda2的环境 注意：anaconda3下对应python3以上的版本，且无法降级python版本！ 具体实现步骤1. 下载anaconda2系列的安装包​ 下载地址 （我下载的： Anaconda2-5.0.1-Linux-x86_64.sh） 2. 在软件所在位置的文件夹内打开终端Terminal窗口切换到刚刚下载好的（Anaconda2-5.0.1-Linux-x86_64.sh）所在位置 3. 逐条执行以下9条命令(报错可能是权限问题，前面加sudo)**1$ bash Anaconda2-5.0.1-Linux-x86_64.sh -b -p $HOME/anaconda3/envs/py2 其中，Anaconda2-5.0.1-Linux-x86_64.sh为所下载的anaconda2软件名，如果不一致需要替换；py2 为环境名称) 12345678$ rm -f $HOME/anaconda3/envs/py2/bin/conda* $ rm -f $HOME/anaconda3/envs/py2/conda-meta/conda-*$ rm -f $HOME/anaconda3/envs/py2/bin/activate$ rm -f $HOME/anaconda3/envs/py2/bin/deactivate$ cd $HOME/anaconda3/envs/py2/bin$ ln -s ../../../bin/conda.$ ln -s ../../../bin/activate.$ ln -s ../../../bin/deactivate. 4. 通过命令switch python来查看当前Python的版本1switch python 5.通过命令source activate py2 来激活anaconda2的环境1source activate py2 6. 通过命令source deactivate py2来返回anaconda3的环境1source deactivate py2 参考链接anaconda3下安装anaconda2","categories":[{"name":"装机篇","slug":"装机篇","permalink":"http://yoursite.com/categories/装机篇/"}],"tags":[{"name":"software install","slug":"software-install","permalink":"http://yoursite.com/tags/software-install/"}]},{"title":"ubantu 虚拟环境创建","slug":"software-install/Create a virtual environment","date":"2019-09-14T12:55:27.000Z","updated":"2019-09-14T12:45:03.157Z","comments":true,"path":"2019/09/14/software-install/Create a virtual environment/","link":"","permalink":"http://yoursite.com/2019/09/14/software-install/Create a virtual environment/","excerpt":"","text":"背景在配置别人的实验环境时，根据作者提供的环境条件逐条安装往往太慢….通常作者会在实验中给requirements.txt文件（里面为实验环境版本配置信息），以下方法介绍如何一次性安装实验所依赖的各种包！ 0. 打开Terminal（pycharm下）先在pycharm所打开的项目，下方菜单切换到项目的Terminal中进行，这样就是对当前项目配备环境。 1.创建虚拟环境 conda create -n 自己虚拟环境的名字 python=3.6（3.6是当前版本号，版本号也可省略） 执行过程中，需要输入 y 2. 激活虚拟环境–2种方式 source activate + 自己虚拟环境的名字（方法1） conda activate + 自己虚拟环境的名字（方法 2） 3.安装所需环境（一般作者把需要的环境写在requirements.txt中 ） pip install -r requirements.txt 即使requirements.txt中所需的环境已安装也没关系，系统会自动解决 4.查看是否安装成功打开电脑的Terminals窗口 ，输入以下命令，会显示电脑中所有的虚拟环境，确认刚刚创建的虚拟环境是否包含在里面。 conda env list 5. 配置实验环境依次点击pycharm下的Project–seeting–add（而不是show all）–切换conda环境–自动检测出刚安装的环境—项目设置","categories":[{"name":"技术篇","slug":"技术篇","permalink":"http://yoursite.com/categories/技术篇/"}],"tags":[]},{"title":"关于转载","slug":"software-install/copyright-reprinted","date":"2019-09-12T13:55:27.000Z","updated":"2019-09-14T03:42:39.387Z","comments":true,"path":"2019/09/12/software-install/copyright-reprinted/","link":"","permalink":"http://yoursite.com/2019/09/12/software-install/copyright-reprinted/","excerpt":"","text":"我希望的转载方式分享链接转载，指向我的博文。 我觉的这是最好的转载方式，互赢。 使用别人的原创换位思考，以后我使用别人的图片和摘选的内容时，我会带上来源地址和作者署名，尊重原创","categories":[{"name":"版权声明","slug":"版权声明","permalink":"http://yoursite.com/categories/版权声明/"}],"tags":[{"name":"软件安装","slug":"软件安装","permalink":"http://yoursite.com/tags/软件安装/"}]},{"title":"MacBook Pro 识别希捷移动硬盘","slug":"software-install/mac+xijieHarddisk","date":"2019-09-12T07:55:27.000Z","updated":"2019-09-14T08:33:11.005Z","comments":true,"path":"2019/09/12/software-install/mac+xijieHarddisk/","link":"","permalink":"http://yoursite.com/2019/09/12/software-install/mac+xijieHarddisk/","excerpt":"","text":"内心OS：被困扰18个小时的question，终于解决，只因思路不清晰，走了很多弯路，太蠢！–20190912 悟！：很多博客只是针对自己电脑遇到的问题给出解决方案，官网是针对所有电脑给出的解决方案，而且官网给出的说明更简洁且可靠！ 设备描述 MacBcook Pro -2018 version：10.14.3 希捷硬盘购买信息：希捷(Seagate) 1TB USB3.0 移动硬盘 睿品新版铭 兼容Mac 问题解决步骤 希捷官网下载 Paragon 驱动程序（注意mac版本） 下载完成后双击软件，按照提示步骤完成安装 重启Mac 将希捷硬盘插入mac 打开 NTFS for Mac 软件，发现移动硬盘已显示，操作如下图 修改移动硬盘名称（若不需要可以直接执行第7步） 点击 右侧 磁盘名称，即可正常访问磁盘 问题解答 如何修改硬盘名称？ 参见步骤6 参考链接1.如何在Mac系统下正确使用硬盘-视频讲解","categories":[{"name":"技术篇","slug":"技术篇","permalink":"http://yoursite.com/categories/技术篇/"}],"tags":[{"name":"软件安装","slug":"软件安装","permalink":"http://yoursite.com/tags/软件安装/"}]},{"title":"Typora（一款比Markdown更好用的软件编辑器）使用方法简介.md","slug":"software-install/Typora使用方法简介","date":"2019-09-10T13:55:27.000Z","updated":"2019-09-19T12:18:11.918Z","comments":true,"path":"2019/09/10/software-install/Typora使用方法简介/","link":"","permalink":"http://yoursite.com/2019/09/10/software-install/Typora使用方法简介/","excerpt":"","text":"Typora编辑器使用方法–参考博客链接Mac下使用Typora的一些简单操作 三个 ~ (英文状态下的波浪线) 回车 就可以输入代码块,如果想让显示行数，需要开启，在Typora–&gt;偏好设置–&gt;Markdown 设置 12 粗体、斜体、==高亮==、删除线、下划线、我是^上标^、我是 下标、超链接 无序列表 无序列表1 无序列表2 有序列表 有序列表 有序列表 任务列表 看电影 听音乐","categories":[{"name":"技术篇","slug":"技术篇","permalink":"http://yoursite.com/categories/技术篇/"}],"tags":[{"name":"软件安装","slug":"软件安装","permalink":"http://yoursite.com/tags/软件安装/"}]},{"title":"softwaerVersion","slug":"software-install/softwaerVersionInquery","date":"2019-05-11T03:57:15.000Z","updated":"2019-05-11T04:54:50.000Z","comments":true,"path":"2019/05/11/software-install/softwaerVersionInquery/","link":"","permalink":"http://yoursite.com/2019/05/11/software-install/softwaerVersionInquery/","excerpt":"","text":"Ubantu 系统本文为在为Ubantu系统安装tensorflow时，因为已有一些软件的安装，所以需要查看确认下 首先 快捷键（Ctrl+Alt+t）打开终端 CUDA nvcc -V ！！ 注意 V 是大写 CUDNN cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR GCCgcc -v ！！ 注意 v 是小写 Anaconda conda -V ！！ 注意 V 是大写 Ubantu cat /proc/version uname -a lsb_release -a 参考博客1.查看 CUDA cudnn 版本 ubuntu查看gcc的版本 查看Anaconda版本、Anaconda和python版本对应关系和快速下载 如何用命令查询 Ubantu 版本号","categories":[{"name":"software","slug":"software","permalink":"http://yoursite.com/categories/software/"}],"tags":[{"name":"Version","slug":"Version","permalink":"http://yoursite.com/tags/Version/"}]},{"title":"推荐系统评价--NDCG方法概述","slug":"MachineLearning/RSC-NDCG","date":"2019-05-02T07:48:25.000Z","updated":"2019-05-02T09:14:46.000Z","comments":true,"path":"2019/05/02/MachineLearning/RSC-NDCG/","link":"","permalink":"http://yoursite.com/2019/05/02/MachineLearning/RSC-NDCG/","excerpt":"","text":"NDCG方法概述NDCG(Normalized Discounted Cumulative Gain)：计算相对复杂。对于排在结位置n处的NDCG的计算公式如下图所示： &ensp;&ensp;&ensp;一个推荐系统返回一些项并形成一个列表，我们想要计算这个列表有多好。每一项都有一个相关的评分值，通常这些评分值是一个非负数。这就是gain（增益）。此外，对于这些没有用户反馈的项，我们通常设置其增益为0。 例如：假设有两个主题，主题1有4个相关网页，主题2有5个相关网页。 (1) 相关度分成从0到r的r+1的等级(r可设定)。当取r=5时，等级设定如下图所示： (应该还有r=1那一级，原文档有误，不过这里不影响理解) (2) 例如现在有一个query={abc}，返回下图左列的Ranked List(URL)，当假设用户的选择与排序结果无关(即每一级都等概率被选中)，则生成的累计增益值如下图最右列所示：&ensp;&ensp;&ensp;我们把这些分数相加，也就是Cumulative Gain（累积增益）。我们更愿意看那些位于列表前面的最相关的项，因此，在把这些分数相加之前，我们将每项除以一个递增的数（通常是该项位置的对数值），也就是折损值，并得到DCG。 (3) 考虑到一般情况下用户会优先点选排在前面的搜索结果，所以应该引入一个折算因子(discounting factor): log(2)/log(1+rank)。这时将获得DCG值(Discounted Cumulative Gain)如下如所示： (4) &ensp;&ensp;&ensp;在用户与用户之间，DCGs没有直接的可比性，所以我们要对它们进行归一化处理。即为了使不同等级上的搜索结果的得分值容易比较，需要将DCG值归一化的到NDCG值。操作如下图所示，首先计算理想返回结果List的DCG值： (5) 然后用DCG/MaxDCG就得到NDCG值，如下图所示： &ensp;&ensp;&ensp; 最糟糕的情况是，当使用非负相关评分时DCG为0。为了得到最好的，我们把测试集中所有的条目置放在理想的次序下，采取的是前K项并计算它们的DCG。然后将原DCG除以理想状态下的DCG并得到NDCG@K，它是一个0到1之间的数。&ensp;&ensp;&ensp;你可能已经注意到，我们使用K表示推荐列表的长度。这个数由专业人员指定。你可以把它想像成是一个用户可能会注意到的多少个项的一个估计值，如10或50这些比较常见的值。 参考博客 推荐系统评价：NDCG方法概述 NDCG及其实现 排序算法常用评价指标计算方式（AUC,MAP,NDCG,MRR） Learning to Rank for IR的评价指标—MAP,NDCG,MRR","categories":[{"name":"Res","slug":"Res","permalink":"http://yoursite.com/categories/Res/"}],"tags":[{"name":"推荐系统","slug":"推荐系统","permalink":"http://yoursite.com/tags/推荐系统/"}]},{"title":"Welcome to NLP-2019-huanhuan-homework-11","slug":"NLP/NLP-RNN-11","date":"2019-04-27T12:00:57.000Z","updated":"2019-04-27T12:44:06.000Z","comments":true,"path":"2019/04/27/NLP/NLP-RNN-11/","link":"","permalink":"http://yoursite.com/2019/04/27/NLP/NLP-RNN-11/","excerpt":"","text":"内容涵盖 RNN的结构。循环神经网络的提出背景、优缺点。着重学习RNN的反向传播、RNN出现的问题（梯度问题、长期依赖问题）、BPTT算法。 双向RNN LSTM、GRU的结构、提出背景、优缺点。 针对梯度消失（LSTM等其他门控RNN）、梯度爆炸（梯度截断）的解决方案。 Text-RNN的原理。 利用Text-RNN模型来进行文本分类。RNN 基础&ensp;&ensp;&ensp;RNN（Recurrent Neural Network）是一类用于处理序列数据的神经网络。首先我们要明确什么是序列数据，摘取百度百科词条：时间序列数据是指在不同时间点上收集到的数据，这类数据反映了某一事物、现象等随时间的变化状态或程度。这是时间序列数据的定义，当然这里也可以不是时间，比如文字序列，但总归序列数据有一个特点——后面的数据跟前面的数据有关系。 (1) RNN的结构及变体&ensp;&ensp;&ensp;我们从基础的神经网络中知道，神经网络包含输入层、隐层、输出层，通过激活函数控制输出，层与层之间通过权值连接。激活函数是事先确定好的，那么神经网络模型通过训练“学“到的东西就蕴含在“权值“中。&ensp;&ensp;&ensp;基础的神经网络只在层与层之间建立了权连接，RNN最大的不同之处就是在层之间的神经元之间也建立的权连接。如图 &ensp;&ensp;&ensp;这是一个标准的RNN结构图，图中每个箭头代表做一次变换，也就是说箭头连接带有权值。左侧是折叠起来的样子，右侧是展开的样子，左侧中h旁边的箭头代表此结构中的“循环“体现在隐层。在展开结构中我们可以观察到，在标准的RNN结构中，隐层的神经元之间也是带有权值的。也就是说，随着序列的不断推进，前面的隐层将会影响后面的隐层。图中O代表输出，y代表样本给出的确定值，L代表损失函数，我们可以看到，“损失“也是随着序列的推荐而不断积累的。除上述特点之外，标准RNN的还有以下特点：1、权值共享，图中的W全是相同的，U和V也一样。2、每一个输入值都只与它本身的那条路线建立权连接，不会和别的神经元连接。 参考资料 一份详细的LSTM和GRU图解 Tensorflow实战(1): 实现深层循环神经网络 从LSTM到Seq2Seq-大数据算法 GitHub - airalcorn2/Recurrent-Convolutional-Neural… GitHub - zhangfazhan/TextRCNN: TextRCNN 文本分类 RCNN tf (推荐) RNN 循环神经网络(RNN, Recurrent Neural Networks)介绍","categories":[{"name":"NLP","slug":"NLP","permalink":"http://yoursite.com/categories/NLP/"}],"tags":[{"name":"RNN","slug":"RNN","permalink":"http://yoursite.com/tags/RNN/"}]},{"title":"Welcome to NLP-2019-huanhuan-homework-10","slug":"NLP/NLP-juanjishenjingwangluo-10","date":"2019-04-25T08:00:35.000Z","updated":"2019-04-25T09:53:32.000Z","comments":true,"path":"2019/04/25/NLP/NLP-juanjishenjingwangluo-10/","link":"","permalink":"http://yoursite.com/2019/04/25/NLP/NLP-juanjishenjingwangluo-10/","excerpt":"","text":"内容涵盖 卷积运算的定义、动机（稀疏权重、参数共享、等变表示）。一维卷积运算和二维卷积运算 反卷积(tf.nn.conv2d_transpose) 池化运算的定义、种类（最大池化、平均池化等）、动机 Text-CNN的原理 利用Text-CNN模型来进行文本分类 1. 卷积运算的定义、动机&ensp;&ensp;&ensp;卷积网络也叫做卷积神经网络，是一种专门用来处理类似具有网格结构的数据的神经网络。例如时间序列数据（可以认为在时间轴上有规律的一维网格数据）、图像数据（可以认为二维的像素网格数据）。卷积神经网络在许多应用中发挥着巨大的作用，比如图像领域。卷积是一种特殊的线性运算，是对两个实值函数的一种数学运算，卷积运算通常用符号 * 来表示。卷积网络是指那些至少在网络的一层中使用卷积运算来代替一般的矩阵乘法运算的神经网络。 &ensp;&ensp;&ensp;卷积运算运用三个重要的思想来帮助改进机器学习系统 ：稀疏交互（sparse interactions)、参数共享（parameter sharing）、等变表示（equivariant pepresentations). (1)卷积运算参考资料1.卷积有多少种？一文读懂深度学习中的各种卷积2.卷积网络笔记3.卷积神经网络入门，基于深度学习的车辆实时检测4.卷积网络——动机","categories":[{"name":"NLP","slug":"NLP","permalink":"http://yoursite.com/categories/NLP/"}],"tags":[{"name":"卷积神经网络基础","slug":"卷积神经网络基础","permalink":"http://yoursite.com/tags/卷积神经网络基础/"}]},{"title":"Welcome to NLP-2019-huanhuan-homework-9","slug":"NLP/NLP-jiandanshenjingwangluo-9","date":"2019-04-23T13:34:24.000Z","updated":"2019-04-23T14:24:20.000Z","comments":true,"path":"2019/04/23/NLP/NLP-jiandanshenjingwangluo-9/","link":"","permalink":"http://yoursite.com/2019/04/23/NLP/NLP-jiandanshenjingwangluo-9/","excerpt":"","text":"内容涵盖 文本表示：从one-hot到word2vec。 词袋模型：离散、高维、稀疏。 分布式表示：连续、低维、稠密。word2vec词向量原理并实践，用来表示文本。 1.文本表示&ensp;&ensp;&ensp;词向量的意思就是通过一个数字组成的向量来表示一个词，这个向量的构成有很多种方法，如one-hot编码、基于共现矩阵的方式、word2vec、动态词向量ELMo等。 (1)one-hot编码&ensp;&ensp;&ensp;one-hot编码又称独热编码、一位有效编码。其方法是使用N位状态寄存器来对N个状态进行编码，每个状态都有它独立的寄存器位，并且在任意时候，其中只有一位有效。假设在一个语料集合中，一共有n个不同的词，则可以使用一个长度为n的向量，对于第i个词（i=0….n-1）,向量index=i处的值为1外，向量其他位置的值都为0，这样就可以唯一的通过[0,0,0,1….0,0]形式的向量表示一个词。one-hot向量比较简单也容易理解，但是有很多问题。比如，加入新词时，整个向量的长度会改变，并且存在维数过高难以计算的问题，以及向量的表示方法很难体现两个词之间的关系，因此一般情况下one-hot向量较少使用。优势：简单易懂不足： 维度灾难、词汇鸿沟（向量之间都是孤立的） （2）基于贡献矩阵的方式 上述矩阵是一个n*n的对称矩阵X，矩阵维数随着词典数量n的增大而增大，可以使用奇异值分解SVD将矩阵维度降低。但是仍存在问题： 矩阵X的维度经常改 由于大部分词并不共现而导致的稀疏性 矩阵维度过高带来的高计算复杂度 （3）基于神经网络的方式（world embedding）：world2vec&ensp;&ensp;&ensp;Embedding层（输入层到隐藏层）是以one hot为输入、中间层节点数为词向量维数的全连接层，这个全连接层的参数就是我们要获取的词向量表！ 2. 词袋模型：离散、高维、稀疏。参考博客 词向量（从one-hot到word2vec） word2vec 中的数学原理详解 word2vec原理推导与代码分析 word2vec3：word2vec中的数学原理详解（四）基于 Hierarchical Softmax 的模型","categories":[{"name":"NLP","slug":"NLP","permalink":"http://yoursite.com/categories/NLP/"}],"tags":[{"name":"简单神经网络","slug":"简单神经网络","permalink":"http://yoursite.com/tags/简单神经网络/"}]},{"title":"Welcome to NLP-2019-huanhuan-homework-8","slug":"NLP/NLP-shenjingwangluojichu-8","date":"2019-04-21T10:52:33.000Z","updated":"2019-04-21T12:25:24.000Z","comments":true,"path":"2019/04/21/NLP/NLP-shenjingwangluojichu-8/","link":"","permalink":"http://yoursite.com/2019/04/21/NLP/NLP-shenjingwangluojichu-8/","excerpt":"","text":"内容涵盖 前馈神经网络、网络层数、输入层、隐藏层、输出层、隐藏单元、激活函数的概念。 感知机相关；利用tensorflow等工具定义简单的几层网络（激活函数sigmoid），递归使用链式法则来实现反向传播。 激活函数的种类以及各自的提出背景、优缺点。（和线性模型对比，线性模型的局限性，去线性化） 深度学习中的正则化（参数范数惩罚：L1正则化、L2正则化；数据集增强；噪声添加；early stop；Dropout层）、正则化的介绍。 深度模型中的优化：参数初始化策略；自适应学习率算法（梯度下降、AdaGrad、RMSProp、Adam；优化算法的选择）；batch norm层（提出背景、解决什么问题、层在训练和测试阶段的计算公式）；layer norm层。 1. 神经网络基础概念&ensp;&ensp;&ensp; 神经网络是机器学习中的一种模型，是一种模仿动物神经网络行为特征，进行分布式并行信息处理的算法数学模型。神经网络最开始是受生物神经系统的启发，为了模拟生物神经系统而出现的。生物神经系统中最基本的计算单元是神经元。 1.1 神经网络模型&ensp;&ensp;&ensp; 所谓神经网络就是将许多个单一“神经元”联结在一起，这样，一个“神经元”的输出就可以是另一个“神经元”的输入。例如，下图就是一个简单的神经网络： 参考博客 人工神经网络知识、激活函数、正则化、优化技术、Batch Normalization、Layer Normalization 神经网络基础","categories":[{"name":"NLP","slug":"NLP","permalink":"http://yoursite.com/categories/NLP/"}],"tags":[{"name":"Network","slug":"Network","permalink":"http://yoursite.com/tags/Network/"}]},{"title":"Welcome to NLP-2019-huanhuan-homework-7","slug":"NLP/LDA","date":"2019-04-19T08:52:33.000Z","updated":"2019-04-19T09:10:16.000Z","comments":true,"path":"2019/04/19/NLP/LDA/","link":"","permalink":"http://yoursite.com/2019/04/19/NLP/LDA/","excerpt":"","text":"内容涵盖 pLSA、共轭先验分布；LDA主题模型原理 LDA应用场景 LDA优缺点 LDA 参数学习 使用LDA生成主题特征，在之前特征的基础上加入主题特征进行文本分类 LSA&ensp;&ensp;&ensp;LSA(latent semantic analysis)潜在语义分析，也被称为 LSI(latent semantic index)，是 Scott Deerwester, Susan T. Dumais 等人在 1990 年提出来的一种新的索引和检索方法。该方法和传统向量空间模型(vector space model)一样使用向量来表示词(terms)和文档(documents)，并通过向量间的关系(如夹角)来判断词及文档间的关系；不同的是，LSA 将词和文档映射到潜在语义空间，从而去除了原始向量空间中的一些“噪音”，提高了信息检索的精确度。 PLSA&ensp;&ensp;&ensp;概率隐语义分析（PLSA）是一个著名的针对文本建模的模型，是一个生成模型。因为加入了主题模型，所以可以很大程度上改善多词一义和一词多义的问题。Hoffmm在1999年提出了概率隐语义分析（Probabilistic Latent Semantic Analysis）。他认为每个主题下都有一个词汇的概率分布，而一篇文章通常由多个主题构成，并且文章中的每个单词都是由某个主题生成的。 LDA&ensp;&ensp;&ensp;LDA（Latent Dirichlet Allocation）是一种文档主题生成模型，也称为一个三层贝叶斯概率模型，包含词、主题和文档三层结构。所谓生成模型，就是说，我们认为一篇文章的每个词都是通过“以一定概率选择了某个主题，并从这个主题中以一定概率选择某个词语”这样一个过程得到。文档到主题服从多项式分布，主题到词服从多项式分布。 &ensp;&ensp;&ensp;LDA是一种非监督机器学习技术，可以用来识别大规模文档集（document collection）或语料库（corpus）中潜藏的主题信息。它采用了词袋（bag of words）的方法，这种方法将每一篇文档视为一个词频向量，从而将文本信息转化为了易于建模的数字信息。但是词袋方法没有考虑词与词之间的顺序，这简化了问题的复杂性，同时也为模型的改进提供了契机。每一篇文档代表了一些主题所构成的一个概率分布，而每一个主题又代表了很多单词所构成的一个概率分布。 &ensp;&ensp;&ensp; LSA（Latent semantic analysis，隐性语义分析）、pLSA（Probabilistic latent semantic analysis，概率隐性语义分析）和 LDA（Latent Dirichlet allocation，隐狄利克雷分配）这三种模型都可以归类到话题模型（Topic model，或称为主题模型）中。相对于比较简单的向量空间模型，主题模型通过引入主题这个概念，更进一步地对文本进行语义层面上的理解 参考博客 朴素贝叶斯 &amp; SVM &amp; LDA文本分类 LDA主题模型 LSA，pLSA原理及其代码实现 主题模型（LDA）(一)–通俗理解与简单应用","categories":[{"name":"NLP","slug":"NLP","permalink":"http://yoursite.com/categories/NLP/"}],"tags":[{"name":"LDA","slug":"LDA","permalink":"http://yoursite.com/tags/LDA/"}]},{"title":"谱聚类（Spectral Clustering）算法概念及应用","slug":"MachineLearning/Pujulei","date":"2019-04-16T07:42:53.000Z","updated":"2019-04-17T07:30:04.000Z","comments":true,"path":"2019/04/16/MachineLearning/Pujulei/","link":"","permalink":"http://yoursite.com/2019/04/16/MachineLearning/Pujulei/","excerpt":"","text":"前言&ensp;&ensp;&ensp;在研究图数据管理方面论文时候，《Label Informed Attributed Network Embedding》文章中提到对图结构表示用的是谱聚类方法，特来了解下该算法的原理。 参考博客正则化1正则化2正则化3 SVM 00.漫谈 Clustering (4): Spectral Clustering00.拉普拉斯矩阵（Laplacian matrix）01.关联矩阵，邻接矩阵，拉普拉斯矩阵 0.聚类系列-谱聚类1.谱聚类（Spectral Clustering）算法介绍 谱聚类（spectral clustering）原理总结 聚类系列-谱聚类 谱聚类算法详解","categories":[{"name":"技术篇","slug":"技术篇","permalink":"http://yoursite.com/categories/技术篇/"}],"tags":[{"name":"聚类","slug":"聚类","permalink":"http://yoursite.com/tags/聚类/"}]},{"title":"Welcome to NLP-2019-huanhuan-homework-5","slug":"NLP/NLP-homework-5-Pushubeiyesi","date":"2019-04-15T11:00:35.000Z","updated":"2019-04-15T14:19:42.000Z","comments":true,"path":"2019/04/15/NLP/NLP-homework-5-Pushubeiyesi/","link":"","permalink":"http://yoursite.com/2019/04/15/NLP/NLP-homework-5-Pushubeiyesi/","excerpt":"","text":"内容涵盖 朴素贝叶斯的原理 朴素贝叶斯应用场景 朴素贝叶斯优缺点 朴素贝叶斯 sklearn 参数学习 利用朴素贝叶斯模型结合 Tf-idf 算法进行文本分类 0.知识回顾(1) 联合概率 &ensp;&ensp;&ensp;P(x)表示x发生的概率，P(y)表示y发生的概率，则 x，y 同时发生的概率为： &ensp;&ensp;&ensp;特别的，当x，y独立时，上式可以写作： &ensp;&ensp;&ensp;原因在于，当x，y独立时，即x的发生与y的发生不相关，因此就有p(x|y)=p(x)，同理p(y|x)=p(y)。 (2) 条件概率 （是联合概率的变形，即把 条件事件 放在了等式左边） (3) 全概率 其中， = 1 ，也就是说对于y的M种（所有）情况都要考虑到。 (3) 贝叶斯 贝叶斯理论指的是，根据一个已发生事件的概率，计算另一个事件的发生概率,贝叶斯公式： 等同于我们经常简略表达： 其中，X: 特征向量 &ensp;&ensp;&ensp; Y：类别&ensp;&ensp;&ensp;&ensp; 先验概率P(X)：是指根据以往经验和分析得到的概率。&ensp;&ensp;&ensp;&ensp;后验概率P(Y|X) ：事情已经发生，要求这件事情发生的原因是由某个因素引起的可能性的大小。&ensp;&ensp;&ensp;&ensp;类条件概率P(X|Y)：在已知某类别的特征空间中，出现特征值 X 的概率密度。 1.朴素贝叶斯原理&ensp;&ensp;&ensp;贝叶斯分类是一类分类算法的总称，这类算法均以贝叶斯定理为基础，故统称为贝叶斯分类。而朴素贝叶斯分类是贝叶斯分类中最简单，也是常见的一种分类方法。 朴素贝叶斯（naïve beyes） 法是基于 贝叶斯定理 与 特征条件独立假设的分类方法。—by李航《统计学习》 基于朴素贝叶斯公式，比较出后验概率的最大值来进行分类，后验概率的计算是由先验概率与类条件概率的乘积得出，先验概率和类条件概率要通过训练数据集得出，即为朴素贝叶斯分类模型，将其保存为中间结果，测试文档进行分类时调用这个中间结果得出后验概率。 &ensp;&ensp;&ensp; 2. 朴素贝叶斯应用场景3.朴素贝叶斯优缺点 优点 (1) 算法逻辑简单,易于实现；(2) 分类过程中时空开销小（假设特征相互独立，只会涉及到二维存储） 缺点 &ensp;&ensp;&ensp;理论上，朴素贝叶斯模型与其他分类方法相比具有最小的误差率。但是实际上并非总是如此，这是因为朴素贝叶斯模型假设属性之间相互独立，这个假设在实际应用中往往是不成立的，在属性个数比较多或者属性之间相关性较大时，分类效果不好。 4.朴素贝叶斯 sklearn 参数学习参考博客 朴素贝叶斯相关的统计学知识 sklearn的机器学习之路：朴素贝叶斯 朴素贝叶斯模型算法研究与实例分析","categories":[{"name":"NLP","slug":"NLP","permalink":"http://yoursite.com/categories/NLP/"}],"tags":[{"name":"朴素贝叶斯","slug":"朴素贝叶斯","permalink":"http://yoursite.com/tags/朴素贝叶斯/"}]},{"title":"Welcome to NLP-2019-huanhuan-homework-4","slug":"NLP/NLP-homework-3","date":"2019-04-13T10:52:33.000Z","updated":"2019-09-13T04:33:59.000Z","comments":true,"path":"2019/04/13/NLP/NLP-homework-3/","link":"","permalink":"http://yoursite.com/2019/04/13/NLP/NLP-homework-3/","excerpt":"","text":"内容涵盖 TF-IDF原理 文本矩阵化，使用词袋模型，以TF-IDF特征值为权重（可以使用Python中TfidfTransformer库） 互信息的原理 使用第二步生成的特征矩阵，利用互信息进行特征筛选 1.TF-IDF原理(1) 定义&ensp;&ensp;&ensp; TF-IDF(Term Frequency - Inverse Document Frequency)，即“词频-逆文本频率”。是一种用于资讯检索与资讯探勘的常用加权技术。TF-IDF是一种统计方法，用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降. (2)思想&ensp;&ensp;&ensp;如果某个词或短语在一篇文章中出现的频率TF高，并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分能力，适合用来分类。TF-IDF实际上就是 TF X IDF，其中TF表示词条在文章Document 中出现的频率；IDF其主要思想就是，如果包含某个词 Word的文档越少，则这个词的区分度就越大，也就是 IDF 越大。 对于如何获取一篇文章的关键词，我们可以计算这边文章出现的所有名词的 TF-IDF，TF-IDF越大，则说明这个名词对这篇文章的区分度就越高，取 TF-IDF 值较大的几个词，就可以当做这篇文章的关键词。 (3) 计算步骤a. 计算词频(TF) 分子是该词在文件 dj 中的出现次数，而分母 则是在文件 dj 中所有字词的出现次数之和。 b. 计算逆文档频率（IDF） 参考博客 文本挖掘预处理之TF-IDF 自然语言处理系列之TF-IDF算法 TF-IDF及其算法 使用不同的方法计算TF-IDF值 sklearn-点互信息和互信息 如何进行特征选择（理论篇）机器学习你会遇到的“坑”","categories":[{"name":"NLP","slug":"NLP","permalink":"http://yoursite.com/categories/NLP/"}],"tags":[{"name":"TF-IDF","slug":"TF-IDF","permalink":"http://yoursite.com/tags/TF-IDF/"}]},{"title":"Welcome to NLP-2019-huanhuan-homework-6","slug":"NLP/NLP-homework-6","date":"2019-04-13T10:52:33.000Z","updated":"2019-04-17T12:11:36.000Z","comments":true,"path":"2019/04/13/NLP/NLP-homework-6/","link":"","permalink":"http://yoursite.com/2019/04/13/NLP/NLP-homework-6/","excerpt":"","text":"内容涵盖 SVM的原理 SVM应用场景 SVM优缺点 SVM sklearn 参数学习 利用SVM模型结合 Tf-idf 算法进行文本分类 SVM的原理支持向量机（SVM）算法基于结构风险最小化原理，将数据集合压缩到支持向量集合，学习得到分类决策函数。这种技术解决了以往需要无穷大样本数量的问题，它只需要将一定数量的文本通过计算抽象成向量化的训练文本数据，提高了分类的精确率。支持向量机（SVM）算法是根据有限的样本信息，在模型的复杂性与学习能力之间寻求最佳折中，以求获得最好的推广能力支持向量机算法. SVM优缺点 专门针对有限样本情况，其目标是得到现有信息下的最优解而不仅仅是样本数量趋于无穷大时的最优值； 算法最终转化为一个二次型寻优问题，理论上得到的是全局最优点，解决了在神经网络方法中无法避免的局部极值问题； 支持向量机算法能同时适用于稠密特征矢量与稀疏特征矢量两种情况，而其他一些文本分类算法不能同时满足两种情况； 支持向量机算法能够找出包含重要分类信息的支持向量，是强有力的增量学习和主动学习工具，在文本分类中具有很大的应用潜力。 参考博客 朴素贝叶斯 &amp; SVM &amp; LDA文本分类","categories":[{"name":"NLP","slug":"NLP","permalink":"http://yoursite.com/categories/NLP/"}],"tags":[{"name":"SVM","slug":"SVM","permalink":"http://yoursite.com/tags/SVM/"}]},{"title":"Welcome to NLP-2019-huanhuan-homework-3","slug":"MachineLearning/tezhentiqu","date":"2019-04-11T12:44:17.000Z","updated":"2019-04-12T08:02:42.000Z","comments":true,"path":"2019/04/11/MachineLearning/tezhentiqu/","link":"","permalink":"http://yoursite.com/2019/04/11/MachineLearning/tezhentiqu/","excerpt":"","text":"内容涵盖 分词的正向最大、逆向最大、双向最大匹配法概念； 词、字符频率统计；（可以使用Python中的collections.Counter模块，也可以自己寻找其他好用的库） 语言模型中unigram、bigram、trigram的概念； unigram、bigram频率统计；（可以使用Python中的collections.Counter模块，也可以自己寻找其他好用的库） 文本矩阵化：要求采用词袋模型且是词级别的矩阵化步骤有：3.1 分词（可采用结巴分词来进行分词操作，其他库也可以）；3.2 去停用词；构造词表。3.3 每篇文档的向量化。 1. 基本文本处理技能&ensp;&ensp;&ensp;Python中分分词工具很多，包括盘古分词、Yaha分词、Jieba分词、清华THULAC等。它们的基本用法都大同小异，本文以结巴分词 为例. (1) 分词算法设计中的几个基本原则： a.颗粒度越大越好：用于进行语义分析的文本分词，要求分词结果的颗粒度越大，即单词的字数越多，所能表示的含义越确切，如：“公安局长”可以分为“公安 局长”、“公安局 长”、“公安局长”都算对，但是要用于语义分析，则“公安局长”的分词结果最好（当然前提是所使用的词典中有这个词） b.切分结果中非词典词越少越好，单字字典词数越少越好，这里的“非词典词”就是不包含在词典中的单字，而“单字字典词”指的是可以独立运用的单字，如“的”、“了”、“和”、“你”、“我”、“他”。例如：“技术和服务”，可以分为“技术 和服 务”以及“技术 和 服务”，但“务”字无法独立成词（即词典中没有），但“和”字可以单独成词（词典中要包含），因此“技术 和服 务”有1个非词典词，而“技术 和 服务”有0个非词典词，因此选用后者。 c.总体词数越少越好，在相同字数的情况下，总词数越少，说明语义单元越少，那么相对的单个语义单元的权重会越大，因此准确性会越高。 (2) 匹配法：&ensp;&ensp;&ensp;最大匹配是指以词典为依据，取词典中最长单词为第一个次取字数量的扫描串，在词典中进行扫描（为提升扫描效率，还可以跟据字数多少设计多个字典，然后根据字数分别从不同字典中进行扫描）。例如：词典中最长词为“我爱北京天安门”共7个汉字，则最大匹配起始字数为7个汉字。然后逐字递减，在对应的词典中进行查找。&ensp;&ensp;下面以“我们在野生动物园玩”详细说明一下这几种匹配方法： a. 正向最大匹配法 正向即从前往后取词，从7-&gt;1，每次减一个字，直到词典命中或剩下1个单字。 第1次：“我们在野生动物”，扫描7字词典，无第2次：“我们在野生动”，扫描6字词典，无……第6次：“我们”，扫描2字词典，有 扫描中止，输出第1个词为“我们”，去除第1个词后开始第2轮扫描，即： 第1次：“在野生动物园玩”，扫描7字词典，无第2次：“在野生动物园”，扫描6字词典，无……第6次：“在野”，扫描2字词典，有 扫描中止，输出第2个词为“在野”，去除第2个词后开始第3轮扫描，即： 第1次：“生动物园玩”，扫描5字词典，无……第4次：“生动”，扫描2字词典，有 扫描中止，输出第3个词为“生动”，第4轮扫描，即： 第1次：“物园玩”，扫描3字词典，无第2次：“物园”，扫描2字词典，无第3次：“物”，扫描1字词典，无 扫描中止，输出第4个词为“物”，非字典词数加1，开始第5轮扫描，即： 第1次：“园玩”，扫描2字词典，无第2次：“园”，扫描1字词典，有 扫描中止，输出第5个词为“园”，单字字典词数加1，开始第6轮扫描，即： 第1次：“玩”，扫描1字字典词，有 扫描中止，输出第6个词为“玩”，单字字典词数加1，整体扫描结束。 *正向最大匹配法，最终切分结果为：“我们/在野/生动/物/园/玩”，其中，单字字典词为2，非词典词为1。 * *b.逆向最大匹配法 * 逆向即从后往前取词，其他逻辑和正向相同。即： 第1轮扫描：“在野生动物园玩”第1次：“在野生动物园玩”，扫描7字词典，无第2次：“野生动物园玩”，扫描6字词典，无……第7次：“玩”，扫描1字词典，有 扫描中止，输出“玩”，单字字典词加1，开始第2轮扫描 第2轮扫描：“们在野生动物园”第1次：“们在野生动物园”，扫描7字词典，无第2次：“在野生动物园”，扫描6字词典，无第3次：“野生动物园”，扫描5字词典，有 扫描中止，输出“野生动物园”，开始第3轮扫描 第3轮扫描：“我们在”第1次：“我们在”，扫描3字词典，无第2次：“们在”，扫描2字词典，无第3次：“在”，扫描1字词典，有 扫描中止，输出“在”，单字字典词加1，开始第4轮扫描 第4轮扫描：“我们”第1次：“我们”，扫描2字词典，有 扫描中止，输出“我们”，整体扫描结束。 逆向最大匹配法，最终切分结果为：“我们/在/野生动物园/玩”，其中，单字字典词为2，非词典词为0。 c.双向最大匹配法 &ensp;&ensp;&ensp;正向最大匹配法和逆向最大匹配法，都有其局限性，我举得例子是正向最大匹配法局限性的例子，逆向也同样存在（如：长春药店，逆向切分为“长/春药店”），因此有人又提出了双向最大匹配法，双向最大匹配法。即，两种算法都切一遍，然后根据大颗粒度词越多越好，非词典词和单字词越少越好的原则，选取其中一种分词结果输出。 如：“我们在野生动物园玩” 正向最大匹配法，最终切分结果为：“我们/在野/生动/物/园/玩”，其中，两字词3个，单字字典词为2，非词典词为1。 逆向最大匹配法，最终切分结果为：“我们/在/野生动物园/玩”，其中，五字词1个，两字词1个，单字字典词为2，非词典词为0。 非字典词：正向(1)&gt;逆向(0)（越少越好） 单字字典词：正向(2)=逆向(2)（越少越好） 总词数：正向(6)&gt;逆向(4)（越少越好） 因此最终输出为逆向结果 参考博客 结巴中文分词理论+实践 中文分词基础原则及正向最大匹配法、逆向最大匹配法、双向最大匹配法的分析","categories":[{"name":"NLP","slug":"NLP","permalink":"http://yoursite.com/categories/NLP/"}],"tags":[]},{"title":"hexo+gitHub 个人博客搭建及更换主题历程--Windows版本（特适合入门小白）","slug":"software-install/hexo-gitHub","date":"2019-04-10T13:55:27.000Z","updated":"2019-10-14T09:00:04.457Z","comments":true,"path":"2019/04/10/software-install/hexo-gitHub/","link":"","permalink":"http://yoursite.com/2019/04/10/software-install/hexo-gitHub/","excerpt":"","text":"内容涵盖 hexo+gitHub 个人博客搭建 搭建过程中遇到的问题及解决方案 更换主题 1. gitHub 创建博客仓库(1) 注册Github（如果已注册可以忽略次此步骤） &ensp;&ensp;&ensp; 详细注册步骤请参考： GitHub网站注册与登陆 (2) Github上新建自己的博客项目（即创建仓库） &ensp;&ensp;注意：仓库名字要和(1)中注册的Github用户名一致！！！ &ensp;&ensp;&ensp;XXX.github.io就是你的博客域名咯~ 2. node 和git 安装(1) 安装 node.js&ensp;&ensp;&ensp;详细安装步骤请参考：nodejs详细安装步骤(2) 安装 Git&ensp;&ensp;&ensp; 详细注册步骤请参考：廖雪峰老师的git安装教程 3. Hexo安装(1) 打开cmd命令编辑器（键盘同时按window+R–输入cmd–回车） (2) 输入全局安装hexo-cli指令 （下载速度有点慢，耐心~~） $ npm install -g hexo-cli **(3) 初始化hexo**(MyHexo文件夹名字自己取) 某盘下新建一个MyHexo文件夹 — 单机鼠标右键 — 选择 Git Bash here– 出现命令窗口，输入下面命令： $ hexo init blog &ensp;&ensp;&ensp;当出现`INFO Start blogging with Hexo!`表示Hexo初始化安装成功。并且MyHexo文件夹中出现 blog 文件夹。 (4) 初体验hexo魅力 ​ 由于初始化hexo 之后source目录下自带一篇hello world文章, 所以依次执行下方两个命令：&ensp;注意：执行下面命令前要先进入blog文件夹中重新打开git命令窗口！！！ $ hexo generate 命令含义： 生成静态文件，等价于(可简写为)： `hexo g` $ hexo server 命令含义： 启动本地服务器，等价于(可简写为)： `hexo s` 打开浏览器，输入网址： http://localhost:4000/ ，即可看到网站初步的模样。&ensp;&ensp;&ensp;若出错提示404等，请参考博客4 4. 如何将github和hexo联系起来？(1) 配置SSH key &ensp;&ensp; &ensp;为什么要配置这个呢？因为你提交代码肯定要拥有你的github权限才可以，但是直接使用用户名和密码太不安全了，所以我们使用ssh key来解决本地和服务器的连接问题。 a. 重新打开 Git 命令窗口，输入下面命令： $ ssh-keygen -t rsa -C \"git@github.com\" //Github的注册邮箱地址 **b.** 一路Enter过来就好，得到的信息如下： Your public key has been saved in /c/Users/user/.ssh/id_rsa.pub. &ensp;&ensp;&ensp;找到该文件并打开，复制里面的所有内容，然后进入Sign in to GitHub：[自己的github设置ssh下](https://github.com/settings/ssh) c. 依次执行下面步骤： 点击 New SSH key —— Title：blog —— Key：输入刚才复制的 —— Add SSH key d. 测试一下是否成功,输入下方命令： $ ssh -T git@github.com //Github的注册邮箱地址 ![SSH](https://github.com/HuanwenW/MyPostImag/blob/master/190410-boke/github-3.png?raw=true) &ensp;&ensp;&ensp;看到上面信息说明SSH已配置成功！ (2) 设置Git的user name和email &ensp;&ensp;&ensp;blog文件夹下的Git命令窗口依次执行下方两个命令： $ git config --global user.name \"liuxianan\" // 你的github用户名，非昵称 $ git config --global user.email \"git@github.com\" // 填写你的github注册邮箱 &ensp;&ensp;&ensp;设置这个是为了便与之后上传到github的page上。 (3) 修改参数及配置deployment&ensp;&ensp;&ensp;在blog目录下，打开_config.yml文件。a. 修改网站相关参数信息&ensp;注意：在每个参数的：后都要加一个空格！！！ title: 焕小妹博客 //博客名字 subtitle: bug //博客副标题 description: Bug多多，欢乐多多 //博客描述 author: 焕焕 //作者 language: zh-CN //zh-CN 表中文 timezone: Asia/Shanghai //时间b. 设置deployment参数信息&ensp;注意：仓库地址后加 .git 结尾！！！ deploy: type: git repository: git@github.com:saucxs/saucxs.github.io.git //Github注册邮箱：Github用户名/Github用户名.github.io.git branch: masterc. 发布到网上,执行下面命令： $ hexo deploy 命令含义： 部署，等价于(可简写为)： `hexo d` &ensp;&ensp;&ensp;若出错提示找不到git，请参考博客5 **d.** 测试是否发布成功 &ensp;&ensp;&ensp;打开浏览器，输入网址： https://你的Github名.github.io ，即可看到部署好的网站，别人也可以访问。 5. 主题不喜欢，换！hexo默认的主题是landscape，可以根据自己的喜好，换你喜欢的主题。(1) 进入github官方主题界面，选择你喜欢的主题！&ensp;&ensp;&ensp;Hexo主题网站地址：https://hexo.io/themes/(2) 复制主题地址&ensp;&ensp;&ensp;假如你喜欢的主题是：Anatolea. 点击进入主题拥有者的博客：b. 找到博主仓库入口进入(一般会有github图标)c. 搜索栏中搜索刚才那个主题的名字d. 点进去这篇博客，复制下载地址(3) 下载主题&ensp;&ensp;&ensp;打开本地博客文件夹(这里对应上文的blog文件夹) —— 打开git命令窗口 —— 输入下面命令：&ensp;注意：仓库地址后加 .themes/Anatole 结尾！！！ $ git clone https://github.com/gaussic/hexo-theme-Anatole.git.themes/Anatole &ensp;&ensp;&ensp;下载完之后会在themes 目录下生成一个名为Anatole文件 **(4) 更改配置文件** &ensp;&ensp;&ensp;更改一下blog工程(文件夹)目录下的配置文件_config.yml，主题名修改一下即可 ![theme](https://github.com/HuanwenW/MyPostImag/blob/master/190410-boke/github-7.jpg?raw=true) **(5) 更新并发布新主题** &ensp;&ensp;&ensp;依次执行下方命令： (每一步作用及执行后界面，可参考上文) $ hexo clean $ hexo g $ hexo s $ hexo d **(6) 测试新主题** &ensp;&ensp;&ensp;打开浏览器，输入网址： https://你的Github名.github.io ，即可看到更新后的主题网站。 ## 6. 创建新的博客及上传！ **(1) 创建新的博客** &ensp;&ensp;&ensp;打开git命令窗口，输入下方命令： $ hexo new '博客文章名字' &ensp;&ensp;&ensp;在目录..\\blog\\source\\_posts下即可看到新建的.md文件 **(2) 遵循Markdown语法书写博客** &ensp;友情链接：**a.** [Markdowen介绍及语法](https://www.jianshu.com/p/7771794c88a1)&ensp;&ensp;&ensp;**b.** [MarkdownPad2安装教程](https://www.jianshu.com/p/5604996dcdbb) (3) 提交博客到GitHub仓库&ensp;&ensp;&ensp;打开本地博客文件夹(这里对应上文的blog文件夹) —— 打开git命令窗口 —— 输入以下命令：a. 清空: $ hexo clean **b.** 生成静态文件: $ hexo g **c.** 将本地运行: $ hexo s **d.** 发布到github的page上 $ hexo d **e.** 查看更新 &ensp;&ensp;&ensp;打开浏览器，输入网址： https://你的Github名.github.io ，即可看到更新的博客。 参考博客 教你免费搭建个人博客，Hexo&amp;Github github+hexo搭建自己的博客网站（二）更换主题yilia 如何更改使用hexo-github搭建博客的主题 theme hexo搭建Github博客上传后，访问网页显示404问题解决方案 hexo d后 ERROR Deployer not found: git hexo搭建模版参照教程","categories":[{"name":"技术篇","slug":"技术篇","permalink":"http://yoursite.com/categories/技术篇/"}],"tags":[{"name":"软件安装","slug":"软件安装","permalink":"http://yoursite.com/tags/软件安装/"}]},{"title":"Markdown 插入图片不友好，如何解决？","slug":"software-install/Markdown-Picture","date":"2019-04-09T13:55:27.000Z","updated":"2019-04-13T11:08:40.000Z","comments":true,"path":"2019/04/09/software-install/Markdown-Picture/","link":"","permalink":"http://yoursite.com/2019/04/09/software-install/Markdown-Picture/","excerpt":"","text":"前奏：&ensp;&ensp;&ensp;想要Markdown中图文并茂记录学习历程，偏偏却卡在了插图上，经过牛牛二虎之力，灰心丧气，终于得救~下面我来综合多篇博客，给入门的小白(git使用都包教)一条生路！ 环境：基于github网页版Markdown图片插入记录 问题来源： MarkDown添加图片的三种方式无法满足我的需求，问题如下： 解决问题思路： （截图中提到的方法1和2结合）即本地图片生成链接（保证图片何时何地都可以显示）+ 插入图片连接方法 前方高能，提高注意力咯！！ 1. GitHub 建立仓库篇第一步： 在GitHub上建立一个图片存储仓库(1) 比如我建立的MyPostImage，用来存储需要的图片。(2) 复制项目地址：第二步： 把Github项目-MyPostImage克隆到本地 ：(1) 新建一个文件夹-githubPicture，在文件夹githubPicture内点击右键–选择Git Bash Here 打开终端，输入命令：(2) 克隆完成后结果如下：(3) 发现原来的文件中出现 MyPostImag文件夹第三步： 在克隆到本地的文件夹中建立一个文件夹–190406-markDown(名字自己取) ：第四步： 把你要用的图片存到文件夹190406-markDown里。第五步： 把更改push到Github仓库： （1） 输入 “ git init “，作用是项目里面会创建一个隐藏的.git文件，执行结果如下： （2） 输入 “ git add . “, 这个是将项目上所有的文件添加到仓库中的意思，如果想添加某个特定的文件，只需把’ . ‘换成这个特定的文件名即可。 （3） 输入 “ git commit -m “first commit “，表示你对这次提交的注释，双引号里面的内容可以根据个人的需要改。例如 “ git commit -m “第一次提交 “ （4） 输入 “git remote add origin https://刚才建立的仓库地址（第一步中提到的）” 将本地的仓库关联到github上。 （5） 输入 “git push -u origin master “，这是把代码上传到github仓库的意思。 （6） 刷新github页面，发现本地新建文件已经出现： 2. 图片生成URL篇（1）打开 190406-markDown 文件夹，双击你需要的图片进入到下面界面：（2）右键选择复制图片地址，然后按照 ![图片名称](复制好的图片地址） 格式，添加到Markdown博文中即可，比如：我下面插入的图3的图片是这样实现的: ![MD-Pic-13.png]（https://github.com/HuanwenW/MyPostImag/blob/master/190406-markDown/MD-Pic-13.png?raw=true） 参考链接 简单三步在Markdown 中插入图片 Github项目（克隆，上传）简单git命令流程使用记录 GitHub上克隆项目到本地","categories":[{"name":"技术篇","slug":"技术篇","permalink":"http://yoursite.com/categories/技术篇/"}],"tags":[{"name":"软件安装","slug":"软件安装","permalink":"http://yoursite.com/tags/软件安装/"}]}]}